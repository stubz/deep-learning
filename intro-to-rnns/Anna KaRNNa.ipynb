{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Anna KaRNNa\n",
    "\n",
    "In this notebook, I'll build a character-wise RNN trained on Anna Karenina, one of my all-time favorite books. It'll be able to generate new text based on the text from the book.\n",
    "\n",
    "This network is based off of Andrej Karpathy's [post on RNNs](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and [implementation in Torch](https://github.com/karpathy/char-rnn). Also, some information [here at r2rt](http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html) and from [Sherjil Ozair](https://github.com/sherjilozair/char-rnn-tensorflow) on GitHub. Below is the general architecture of the character-wise RNN.\n",
    "\n",
    "<img src=\"assets/charseq.jpeg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First we'll load the text file and convert it into integers for our network to use. Here I'm creating a couple dictionaries to convert the characters to and from integers. Encoding the characters as integers makes it easier to use as input in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('anna.txt', 'r') as f:\n",
    "    text=f.read()\n",
    "vocab = set(text)\n",
    "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
    "int_to_vocab = dict(enumerate(vocab))\n",
    "chars = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's check out the first 100 characters, make sure everything is peachy. According to the [American Book Review](http://americanbookreview.org/100bestlines.asp), this is the 6th best first line of a book ever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And we can see the characters encoded as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81, 46, 78, 70, 49, 15, 82, 62,  9, 29, 29, 29, 63, 78, 70, 70, 69,\n",
       "       62, 42, 78, 54, 79, 50, 79, 15,  6, 62, 78, 82, 15, 62, 78, 50, 50,\n",
       "       62, 78, 50, 79, 37, 15, 11, 62, 15, 65, 15, 82, 69, 62, 73, 33, 46,\n",
       "       78, 70, 70, 69, 62, 42, 78, 54, 79, 50, 69, 62, 79,  6, 62, 73, 33,\n",
       "       46, 78, 70, 70, 69, 62, 79, 33, 62, 79, 49,  6, 62,  8, 59, 33, 29,\n",
       "       59, 78, 69, 74, 29, 29, 61, 65, 15, 82, 69, 49, 46, 79, 33], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since the network is working with individual characters, it's similar to a classification problem in which we are trying to predict the next character from the previous text.  Here's how many 'classes' our network has to pick from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(chars)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Making training and validation batches\n",
    "\n",
    "Now I need to split up the data into batches, and into training and validation sets. I should be making a test set here, but I'm not going to worry about that. My test will be if the network can generate new text.\n",
    "\n",
    "Here I'll make both input and target arrays. The targets are the same as the inputs, except shifted one character over. I'll also drop the last bit of data so that I'll only have completely full batches.\n",
    "\n",
    "The idea here is to make a 2D matrix where the number of rows is equal to the batch size. Each row will be one long concatenated string from the character data. We'll split this data into a training set and validation set using the `split_frac` keyword. This will keep 90% of the batches in the training set, the other 10% in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def split_data(chars, batch_size, num_steps, split_frac=0.9):\n",
    "    \"\"\" \n",
    "    Split character data into training and validation sets, inputs and targets for each set.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    chars: character array\n",
    "    batch_size: Size of examples in each of batch\n",
    "    num_steps: Number of sequence steps to keep in the input and pass to the network\n",
    "    split_frac: Fraction of batches to keep in the training set\n",
    "    \n",
    "    \n",
    "    Returns train_x, train_y, val_x, val_y\n",
    "    \"\"\"\n",
    "    \n",
    "    slice_size = batch_size * num_steps\n",
    "    n_batches = int(len(chars) / slice_size)\n",
    "    \n",
    "    # Drop the last few characters to make only full batches\n",
    "    x = chars[: n_batches*slice_size]\n",
    "    y = chars[1: n_batches*slice_size + 1]\n",
    "    \n",
    "    # Split the data into batch_size slices, then stack them into a 2D matrix \n",
    "    x = np.stack(np.split(x, batch_size))\n",
    "    y = np.stack(np.split(y, batch_size))\n",
    "    \n",
    "    # Now x and y are arrays with dimensions batch_size x n_batches*num_steps\n",
    "    \n",
    "    # Split into training and validation sets, keep the first split_frac batches for training\n",
    "    split_idx = int(n_batches*split_frac)\n",
    "    train_x, train_y= x[:, :split_idx*num_steps], y[:, :split_idx*num_steps]\n",
    "    val_x, val_y = x[:, split_idx*num_steps:], y[:, split_idx*num_steps:]\n",
    "    \n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size  = 10\n",
    "num_steps = 50\n",
    "slice_size = batch_size*num_steps\n",
    "n_batches = int(len(chars)/slice_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now I'll make my data sets and we can check out what's going on here. Here I'm going to use a batch size of 10 and 50 sequence steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y = split_data(chars, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 178650)\n",
      "(10, 19850)\n",
      "198500\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(val_x.shape)\n",
    "print(train_x.shape[1]+val_x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Looking at the size of this array, we see that we have rows equal to the batch size. When we want to get a batch out of here, we can grab a subset of this array that contains all the rows but has a width equal to the number of steps in the sequence. The first batch looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31, 66, 57, 74, 78, 61, 76,  3, 16,  1,  0,  1,  0,  1,  0, 38, 57,\n",
       "        74, 74, 81,  3, 64, 57, 69, 65, 70, 65, 61, 75,  3, 57, 76, 61,  3,\n",
       "        57, 70, 70,  3, 57, 70, 65, 67, 61, 26,  3, 61, 80, 61, 76, 81],\n",
       "       [ 3, 75, 70, 61, 61, 80, 61,  3, 71, 64,  3, 66, 65, 75,  3, 62, 76,\n",
       "        61, 75, 75,  3, 59, 71, 57, 78, 13,  3,  4, 37,  7, 80, 61,  3, 75,\n",
       "        77, 59, 66,  3, 57, 72,  3, 65, 62, 61, 57,  3, 64, 71, 76,  3],\n",
       "       [61, 76, 15,  4,  1,  0,  1,  0, 47, 78, 61, 74, 57, 72,  3, 29, 76,\n",
       "        67, 57, 62, 81, 61, 80, 65, 78, 59, 66,  3, 75, 69, 65, 70, 61, 62,\n",
       "         3, 66, 57, 76, 62, 70, 81,  3, 74, 61, 76, 59, 61, 74, 78, 65],\n",
       "       [75,  3, 69, 61, 57, 72, 65, 72, 63,  1,  0, 59, 70, 61, 57, 76, 70,\n",
       "        81, 13,  3, 71, 76,  3, 60, 61, 59, 57, 77, 75, 61,  3, 66, 65, 75,\n",
       "         3, 60, 76, 71, 78, 66, 61, 76,  3, 79, 71, 77, 70, 62,  3, 72],\n",
       "       [66, 61, 76, 13,  3, 36, 65, 72, 71, 63, 61, 72,  3, 79, 57, 72, 78,\n",
       "        75,  3, 75, 71, 69, 61,  3, 78, 57, 76, 13,  4,  3, 75, 57, 65, 62,\n",
       "         3, 78, 66, 61,  3, 81, 71, 77, 72, 63,  3, 79, 71, 69, 57, 72],\n",
       "       [62,  1,  0, 75, 71,  3, 66, 61,  3, 66, 57, 62,  3, 62, 61, 59, 65,\n",
       "        62, 61, 62,  3, 78, 66, 57, 78,  3, 75, 71,  3, 65, 78,  3, 69, 77,\n",
       "        75, 78,  3, 60, 61, 15,  3, 32, 77, 78,  3, 66, 61,  3, 66, 57],\n",
       "       [65, 59, 65, 72, 63,  3, 66, 61, 76,  3, 66, 77, 75, 60, 57, 72, 62,\n",
       "         7, 75,  3, 64, 57, 59, 61,  3, 71, 64,  3, 62, 65, 75, 69, 57, 81,\n",
       "        13,  3,  4, 71, 76,  3, 63, 71,  3, 71, 72, 26,  1,  0, 63, 71],\n",
       "       [61, 72,  3, 71, 64, 64, 61, 72, 62, 61, 62,  3, 57, 78,  3, 66, 65,\n",
       "        75,  3, 68, 61, 57, 70, 71, 77, 75, 81, 26,  3, 75, 66, 61,  3, 79,\n",
       "        57, 75,  1,  0, 57, 72, 63, 76, 81,  3, 78, 66, 57, 78,  3, 78],\n",
       "       [75,  3, 78, 57, 70, 67, 65, 72, 63,  3, 57, 78,  3, 78, 66, 61,  3,\n",
       "        66, 65, 63, 66,  3, 78, 57, 60, 70, 61, 15,  1,  0,  1,  0,  4, 50,\n",
       "        66, 57, 78,  7, 75,  3, 78, 66, 61,  3, 72, 61, 79,  3, 63, 61],\n",
       "       [57, 69, 61,  3, 59, 65, 76, 59, 70, 61,  3, 78, 66, 57, 78,  3, 75,\n",
       "        66, 61,  3, 66, 57, 62,  3, 60, 61, 61, 72,  3, 76, 71, 77, 72, 62,\n",
       "         3, 75, 71,  3, 71, 64, 78, 61, 72,  3, 60, 61, 64, 71, 76, 61]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:,:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I'll write another function to grab batches out of the arrays made by `split_data`. Here each batch will be a sliding window on these arrays with size `batch_size X num_steps`. For example, if we want our network to train on a sequence of 100 characters, `num_steps = 100`. For the next batch, we'll shift this window the next sequence of `num_steps` characters. In this way we can feed batches to the network and the cell states will continue through on each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batch(arrs, num_steps):\n",
    "    batch_size, slice_size = arrs[0].shape\n",
    "    \n",
    "    n_batches = int(slice_size/num_steps)\n",
    "    for b in range(n_batches):\n",
    "        yield [x[:, b*num_steps: (b+1)*num_steps] for x in arrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the model\n",
    "\n",
    "Below is a function where I build the graph for the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(num_classes, batch_size=50, num_steps=50, lstm_size=128, num_layers=2,\n",
    "              learning_rate=0.001, grad_clip=5, sampling=False):\n",
    "    \n",
    "    # When we're using this network for sampling later, we'll be passing in\n",
    "    # one character at a time, so providing an option for that\n",
    "    if sampling == True:\n",
    "        batch_size, num_steps = 1, 1\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32, [batch_size, num_steps], name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, [batch_size, num_steps], name='targets')\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    # One-hot encoding the input and target characters\n",
    "    x_one_hot = tf.one_hot(inputs, num_classes)\n",
    "    y_one_hot = tf.one_hot(targets, num_classes)\n",
    "\n",
    "    ### Build the RNN layers\n",
    "    # Use a basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Add dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * num_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    ### Run the data through the RNN layers\n",
    "    # This makes a list where each element is on step in the sequence\n",
    "    rnn_inputs = [tf.squeeze(i, squeeze_dims=[1]) for i in tf.split(x_one_hot, num_steps, 1)]\n",
    "    \n",
    "    # Run each sequence step through the RNN and collect the outputs\n",
    "    outputs, state = tf.contrib.rnn.static_rnn(cell, rnn_inputs, initial_state=initial_state)\n",
    "    final_state = state\n",
    "    \n",
    "    # Reshape output so it's a bunch of rows, one output row for each step for each batch\n",
    "    seq_output = tf.concat(outputs, axis=1)\n",
    "    output = tf.reshape(seq_output, [-1, lstm_size])\n",
    "    \n",
    "    # Now connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        softmax_w = tf.Variable(tf.truncated_normal((lstm_size, num_classes), stddev=0.1))\n",
    "        softmax_b = tf.Variable(tf.zeros(num_classes))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and batch\n",
    "    logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    preds = tf.nn.softmax(logits, name='predictions')\n",
    "    \n",
    "    # Reshape the targets to match the logits\n",
    "    y_reshaped = tf.reshape(y_one_hot, [-1, num_classes])\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "    cost = tf.reduce_mean(loss)\n",
    "\n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), grad_clip)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    # Export the nodes\n",
    "    # NOTE: I'm using a namedtuple here because I think they are cool\n",
    "    export_nodes = ['inputs', 'targets', 'initial_state', 'final_state',\n",
    "                    'keep_prob', 'cost', 'preds', 'optimizer']\n",
    "    Graph = namedtuple('Graph', export_nodes)\n",
    "    local_dict = locals()\n",
    "    graph = Graph(*[local_dict[each] for each in export_nodes])\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Here I'm defining the hyperparameters for the network. \n",
    "\n",
    "* `batch_size` - Number of sequences running through the network in one pass.\n",
    "* `num_steps` - Number of characters in the sequence the network is trained on. Larger is better typically, the network will learn more long range dependencies. But it takes longer to train. 100 is typically a good number here.\n",
    "* `lstm_size` - The number of units in the hidden layers.\n",
    "* `num_layers` - Number of hidden LSTM layers to use\n",
    "* `learning_rate` - Learning rate for training\n",
    "* `keep_prob` - The dropout keep probability when training. If you're network is overfitting, try decreasing this.\n",
    "\n",
    "Here's some good advice from Andrej Karpathy on training the network. I'm going to write it in here for your benefit, but also link to [where it originally came from](https://github.com/karpathy/char-rnn#tips-and-tricks).\n",
    "\n",
    "> ## Tips and Tricks\n",
    "\n",
    ">### Monitoring Validation Loss vs. Training Loss\n",
    ">If you're somewhat new to Machine Learning or Neural Networks it can take a bit of expertise to get good models. The most important quantity to keep track of is the difference between your training loss (printed during training) and the validation loss (printed once in a while when the RNN is run on the validation data (by default every 1000 iterations)). In particular:\n",
    "\n",
    "> - If your training loss is much lower than validation loss then this means the network might be **overfitting**. Solutions to this are to decrease your network size, or to increase dropout. For example you could try dropout of 0.5 and so on.\n",
    "> - If your training/validation loss are about equal then your model is **underfitting**. Increase the size of your model (either number of layers or the raw number of neurons per layer)\n",
    "\n",
    "> ### Approximate number of parameters\n",
    "\n",
    "> The two most important parameters that control the model are `lstm_size` and `num_layers`. I would advise that you always use `num_layers` of either 2/3. The `lstm_size` can be adjusted based on how much data you have. The two important quantities to keep track of here are:\n",
    "\n",
    "> - The number of parameters in your model. This is printed when you start training.\n",
    "> - The size of your dataset. 1MB file is approximately 1 million characters.\n",
    "\n",
    ">These two should be about the same order of magnitude. It's a little tricky to tell. Here are some examples:\n",
    "\n",
    "> - I have a 100MB dataset and I'm using the default parameter settings (which currently print 150K parameters). My data size is significantly larger (100 mil >> 0.15 mil), so I expect to heavily underfit. I am thinking I can comfortably afford to make `lstm_size` larger.\n",
    "> - I have a 10MB dataset and running a 10 million parameter model. I'm slightly nervous and I'm carefully monitoring my validation loss. If it's larger than my training loss then I may want to try to increase dropout a bit and see if that helps the validation loss.\n",
    "\n",
    "> ### Best models strategy\n",
    "\n",
    ">The winning strategy to obtaining very good models (if you have the compute time) is to always err on making the network larger (as large as you're willing to wait for it to compute) and then try different dropout values (between 0,1). Whatever model has the best validation performance (the loss, written in the checkpoint filename, low is good) is the one you should use in the end.\n",
    "\n",
    ">It is very common in deep learning to run many different models with many different hyperparameter settings, and in the end take whatever checkpoint gave the best validation performance.\n",
    "\n",
    ">By the way, the size of your training and validation splits are also parameters. Make sure you have a decent amount of data in your validation set or otherwise the validation performance will be noisy and not very informative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_steps = 100 \n",
    "lstm_size = 512\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "\n",
    "Time for training which is pretty straightforward. Here I pass in some data, and get an LSTM state back. Then I pass that state back in to the network so the next batch can continue the state from the previous batch. And every so often (set by `save_every_n`) I calculate the validation loss and save a checkpoint.\n",
    "\n",
    "Here I'm saving checkpoints with the format\n",
    "\n",
    "`i{iteration number}_l{# hidden layer units}_v{validation loss}.ckpt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch 1/20 ', 'Iteration 1/3620', 'Training loss: 4.4310', '9.0600 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 2/3620', 'Training loss: 4.3898', '7.0425 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 3/3620', 'Training loss: 4.2281', '7.5259 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 4/3620', 'Training loss: 4.4850', '9.9146 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 5/3620', 'Training loss: 4.4698', '6.7199 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 6/3620', 'Training loss: 4.3801', '8.3257 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 7/3620', 'Training loss: 4.2841', '6.4296 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 8/3620', 'Training loss: 4.1982', '9.2441 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 9/3620', 'Training loss: 4.1270', '11.9799 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 10/3620', 'Training loss: 4.0624', '6.6828 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 11/3620', 'Training loss: 4.0080', '7.2494 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 12/3620', 'Training loss: 3.9606', '6.4536 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 13/3620', 'Training loss: 3.9177', '6.2953 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 14/3620', 'Training loss: 3.8812', '6.3182 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 15/3620', 'Training loss: 3.8496', '8.5828 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 16/3620', 'Training loss: 3.8190', '6.5820 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 17/3620', 'Training loss: 3.7910', '8.3362 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 18/3620', 'Training loss: 3.7658', '6.5949 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 19/3620', 'Training loss: 3.7431', '7.1774 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 20/3620', 'Training loss: 3.7217', '8.7383 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 21/3620', 'Training loss: 3.7015', '7.1419 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 22/3620', 'Training loss: 3.6826', '8.5014 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 23/3620', 'Training loss: 3.6663', '6.9839 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 24/3620', 'Training loss: 3.6506', '7.1609 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 25/3620', 'Training loss: 3.6360', '6.7024 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 26/3620', 'Training loss: 3.6222', '6.5580 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 27/3620', 'Training loss: 3.6095', '8.2039 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 28/3620', 'Training loss: 3.5970', '6.7063 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 29/3620', 'Training loss: 3.5853', '6.8193 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 30/3620', 'Training loss: 3.5737', '6.7313 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 31/3620', 'Training loss: 3.5632', '6.5027 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 32/3620', 'Training loss: 3.5535', '6.3120 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 33/3620', 'Training loss: 3.5448', '6.4724 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 34/3620', 'Training loss: 3.5356', '7.1813 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 35/3620', 'Training loss: 3.5264', '8.1665 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 36/3620', 'Training loss: 3.5188', '8.2111 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 37/3620', 'Training loss: 3.5110', '7.5293 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 38/3620', 'Training loss: 3.5032', '7.7531 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 39/3620', 'Training loss: 3.4957', '8.1652 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 40/3620', 'Training loss: 3.4885', '7.7235 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 41/3620', 'Training loss: 3.4812', '7.6742 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 42/3620', 'Training loss: 3.4748', '7.6926 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 43/3620', 'Training loss: 3.4686', '7.8227 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 44/3620', 'Training loss: 3.4624', '8.7381 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 45/3620', 'Training loss: 3.4563', '9.4355 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 46/3620', 'Training loss: 3.4506', '8.9008 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 47/3620', 'Training loss: 3.4451', '7.4111 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 48/3620', 'Training loss: 3.4397', '6.5590 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 49/3620', 'Training loss: 3.4350', '6.5191 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 50/3620', 'Training loss: 3.4306', '6.7202 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 51/3620', 'Training loss: 3.4261', '6.4437 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 52/3620', 'Training loss: 3.4213', '6.9898 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 53/3620', 'Training loss: 3.4169', '6.7688 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 54/3620', 'Training loss: 3.4125', '6.5668 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 55/3620', 'Training loss: 3.4083', '6.4423 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 56/3620', 'Training loss: 3.4044', '6.4298 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 57/3620', 'Training loss: 3.4003', '6.4800 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 58/3620', 'Training loss: 3.3964', '6.4476 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 59/3620', 'Training loss: 3.3927', '6.7828 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 60/3620', 'Training loss: 3.3894', '6.5478 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 61/3620', 'Training loss: 3.3857', '6.5587 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 62/3620', 'Training loss: 3.3821', '6.5282 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 63/3620', 'Training loss: 3.3787', '8.8737 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 64/3620', 'Training loss: 3.3755', '7.9912 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 65/3620', 'Training loss: 3.3725', '7.5337 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 66/3620', 'Training loss: 3.3696', '7.8232 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 67/3620', 'Training loss: 3.3664', '7.2984 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 68/3620', 'Training loss: 3.3633', '7.3139 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 69/3620', 'Training loss: 3.3603', '6.9118 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 70/3620', 'Training loss: 3.3574', '6.9776 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 71/3620', 'Training loss: 3.3546', '7.6553 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 72/3620', 'Training loss: 3.3519', '6.9473 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 73/3620', 'Training loss: 3.3491', '8.0281 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 74/3620', 'Training loss: 3.3466', '7.1071 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 75/3620', 'Training loss: 3.3443', '6.9786 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 76/3620', 'Training loss: 3.3416', '7.7368 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 77/3620', 'Training loss: 3.3390', '7.4774 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 78/3620', 'Training loss: 3.3367', '7.0289 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 79/3620', 'Training loss: 3.3343', '6.9521 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 80/3620', 'Training loss: 3.3322', '7.0769 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 81/3620', 'Training loss: 3.3297', '7.6510 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 82/3620', 'Training loss: 3.3273', '8.0818 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 83/3620', 'Training loss: 3.3249', '7.7907 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 84/3620', 'Training loss: 3.3228', '7.7011 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 85/3620', 'Training loss: 3.3204', '7.8451 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 86/3620', 'Training loss: 3.3181', '7.8378 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 87/3620', 'Training loss: 3.3157', '7.5953 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 88/3620', 'Training loss: 3.3131', '6.8265 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 89/3620', 'Training loss: 3.3109', '6.4787 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 90/3620', 'Training loss: 3.3084', '6.0920 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 91/3620', 'Training loss: 3.3060', '3603.9364 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 92/3620', 'Training loss: 3.3040', '9.8786 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 93/3620', 'Training loss: 3.3017', '13.9487 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 94/3620', 'Training loss: 3.2997', '6.0177 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 95/3620', 'Training loss: 3.2975', '6.7812 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 96/3620', 'Training loss: 3.2955', '6.9513 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 97/3620', 'Training loss: 3.2934', '6.7810 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 98/3620', 'Training loss: 3.2911', '6.9136 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 99/3620', 'Training loss: 3.2890', '6.8401 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 100/3620', 'Training loss: 3.2869', '6.4593 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 101/3620', 'Training loss: 3.2849', '6.5221 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 102/3620', 'Training loss: 3.2827', '6.6187 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 103/3620', 'Training loss: 3.2805', '6.3814 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 104/3620', 'Training loss: 3.2782', '6.5795 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 105/3620', 'Training loss: 3.2760', '6.5113 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 106/3620', 'Training loss: 3.2738', '6.4037 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 107/3620', 'Training loss: 3.2716', '6.3627 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 108/3620', 'Training loss: 3.2696', '6.4026 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 109/3620', 'Training loss: 3.2672', '6.4118 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 110/3620', 'Training loss: 3.2648', '6.4288 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 111/3620', 'Training loss: 3.2624', '6.3042 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 112/3620', 'Training loss: 3.2600', '7.1208 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 113/3620', 'Training loss: 3.2577', '6.5269 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 114/3620', 'Training loss: 3.2551', '7.8392 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 115/3620', 'Training loss: 3.2530', '6.5115 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 116/3620', 'Training loss: 3.2508', '6.4385 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 117/3620', 'Training loss: 3.2488', '1803.6477 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 118/3620', 'Training loss: 3.2466', '12.2724 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 119/3620', 'Training loss: 3.2441', '10.7561 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 120/3620', 'Training loss: 3.2419', '6.4345 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 121/3620', 'Training loss: 3.2397', '6.2756 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 122/3620', 'Training loss: 3.2374', '6.0781 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 123/3620', 'Training loss: 3.2351', '6.1312 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 124/3620', 'Training loss: 3.2329', '6.0800 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 125/3620', 'Training loss: 3.2306', '6.1345 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 126/3620', 'Training loss: 3.2282', '6.0745 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 127/3620', 'Training loss: 3.2257', '6.0644 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 128/3620', 'Training loss: 3.2233', '6.0646 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 129/3620', 'Training loss: 3.2207', '6.0266 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 130/3620', 'Training loss: 3.2180', '6.0205 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 131/3620', 'Training loss: 3.2155', '6.0675 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 132/3620', 'Training loss: 3.2130', '6.0099 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 133/3620', 'Training loss: 3.2104', '6.0864 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 134/3620', 'Training loss: 3.2078', '6.0374 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 135/3620', 'Training loss: 3.2051', '6.0647 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 136/3620', 'Training loss: 3.2024', '6.0184 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 137/3620', 'Training loss: 3.1994', '6.0177 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 138/3620', 'Training loss: 3.1968', '6.5909 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 139/3620', 'Training loss: 3.1942', '6.0943 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 140/3620', 'Training loss: 3.1912', '6.2179 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 141/3620', 'Training loss: 3.1882', '6.1673 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 142/3620', 'Training loss: 3.1856', '6.0670 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 143/3620', 'Training loss: 3.1827', '6.0941 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 144/3620', 'Training loss: 3.1798', '6.0406 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 145/3620', 'Training loss: 3.1770', '6.1437 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 146/3620', 'Training loss: 3.1739', '6.0659 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 147/3620', 'Training loss: 3.1710', '6.1216 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 148/3620', 'Training loss: 3.1682', '6.5034 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 149/3620', 'Training loss: 3.1654', '156.8990 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 150/3620', 'Training loss: 3.1626', '9.2974 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 151/3620', 'Training loss: 3.1598', '10.5078 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 152/3620', 'Training loss: 3.1570', '8.2264 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 153/3620', 'Training loss: 3.1540', '8.0123 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 154/3620', 'Training loss: 3.1511', '7.2489 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 155/3620', 'Training loss: 3.1482', '8.8987 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 156/3620', 'Training loss: 3.1453', '10.0949 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 157/3620', 'Training loss: 3.1424', '7.0183 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 158/3620', 'Training loss: 3.1396', '6.7401 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 159/3620', 'Training loss: 3.1362', '6.6925 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 160/3620', 'Training loss: 3.1332', '6.7542 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 161/3620', 'Training loss: 3.1300', '7.9651 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 162/3620', 'Training loss: 3.1268', '6.9392 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 163/3620', 'Training loss: 3.1235', '7.1749 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 164/3620', 'Training loss: 3.1201', '6.5563 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 165/3620', 'Training loss: 3.1168', '7.0498 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 166/3620', 'Training loss: 3.1134', '7.0400 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 167/3620', 'Training loss: 3.1101', '7.4691 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 168/3620', 'Training loss: 3.1067', '6.8489 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 169/3620', 'Training loss: 3.1033', '7.7388 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 170/3620', 'Training loss: 3.1001', '7.3977 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 171/3620', 'Training loss: 3.0967', '6.7608 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 172/3620', 'Training loss: 3.0934', '7.4297 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 173/3620', 'Training loss: 3.0903', '8.7758 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 174/3620', 'Training loss: 3.0870', '8.3975 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 175/3620', 'Training loss: 3.0837', '8.5411 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 176/3620', 'Training loss: 3.0805', '6.2322 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 177/3620', 'Training loss: 3.0773', '6.1099 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 178/3620', 'Training loss: 3.0743', '6.0684 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 179/3620', 'Training loss: 3.0713', '6.0974 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 180/3620', 'Training loss: 3.0682', '6.8755 sec/batch')\n",
      "('Epoch 1/20 ', 'Iteration 181/3620', 'Training loss: 3.0650', '6.0722 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 182/3620', 'Training loss: 2.5399', '7.0328 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 183/3620', 'Training loss: 2.5006', '6.5803 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 184/3620', 'Training loss: 2.4757', '6.5840 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 185/3620', 'Training loss: 2.4684', '6.2280 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 186/3620', 'Training loss: 2.4619', '6.8259 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 187/3620', 'Training loss: 2.4636', '6.1251 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 188/3620', 'Training loss: 2.4596', '6.6233 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 189/3620', 'Training loss: 2.4557', '6.6322 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 190/3620', 'Training loss: 2.4554', '6.5758 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 191/3620', 'Training loss: 2.4524', '7.4300 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 192/3620', 'Training loss: 2.4522', '7.3485 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 193/3620', 'Training loss: 2.4506', '8.4885 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 194/3620', 'Training loss: 2.4491', '8.9010 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 195/3620', 'Training loss: 2.4470', '7.9698 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 196/3620', 'Training loss: 2.4479', '8.5351 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 197/3620', 'Training loss: 2.4462', '7.0214 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 198/3620', 'Training loss: 2.4438', '9.4100 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 199/3620', 'Training loss: 2.4429', '11.2920 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 200/3620', 'Training loss: 2.4429', '9.0278 sec/batch')\n",
      "('Validation loss:', 2.3628299, 'Saving checkpoint!')\n",
      "('Epoch 2/20 ', 'Iteration 201/3620', 'Training loss: 2.4428', '7.5716 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 202/3620', 'Training loss: 2.4425', '6.4460 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 203/3620', 'Training loss: 2.4400', '6.3923 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 204/3620', 'Training loss: 2.4377', '6.4596 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 205/3620', 'Training loss: 2.4361', '6.3723 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 206/3620', 'Training loss: 2.4339', '6.4438 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 207/3620', 'Training loss: 2.4324', '6.4227 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 208/3620', 'Training loss: 2.4307', '6.4413 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 209/3620', 'Training loss: 2.4279', '9.1634 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 210/3620', 'Training loss: 2.4263', '6.5464 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 211/3620', 'Training loss: 2.4249', '7.6309 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 212/3620', 'Training loss: 2.4232', '6.7518 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 213/3620', 'Training loss: 2.4218', '6.9705 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 214/3620', 'Training loss: 2.4199', '7.4149 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 215/3620', 'Training loss: 2.4188', '11.5220 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 216/3620', 'Training loss: 2.4166', '7.5967 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 217/3620', 'Training loss: 2.4153', '6.5504 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 218/3620', 'Training loss: 2.4138', '6.5214 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 219/3620', 'Training loss: 2.4115', '6.6063 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 220/3620', 'Training loss: 2.4101', '7.7938 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 221/3620', 'Training loss: 2.4084', '6.7289 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 222/3620', 'Training loss: 2.4059', '6.6714 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 223/3620', 'Training loss: 2.4043', '6.9227 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 224/3620', 'Training loss: 2.4025', '6.7635 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 225/3620', 'Training loss: 2.4006', '6.6703 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 226/3620', 'Training loss: 2.3987', '6.6842 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 227/3620', 'Training loss: 2.3966', '8.4745 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 228/3620', 'Training loss: 2.3949', '8.5063 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 229/3620', 'Training loss: 2.3926', '7.5794 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 230/3620', 'Training loss: 2.3909', '8.0486 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 231/3620', 'Training loss: 2.3895', '6.5077 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 232/3620', 'Training loss: 2.3880', '6.1337 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 233/3620', 'Training loss: 2.3862', '6.0907 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 234/3620', 'Training loss: 2.3849', '6.6018 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 235/3620', 'Training loss: 2.3831', '6.0731 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 236/3620', 'Training loss: 2.3816', '6.0893 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 237/3620', 'Training loss: 2.3802', '6.1404 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 238/3620', 'Training loss: 2.3786', '6.0223 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 239/3620', 'Training loss: 2.3769', '6.0297 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 240/3620', 'Training loss: 2.3752', '6.0907 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 241/3620', 'Training loss: 2.3741', '6.0704 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 242/3620', 'Training loss: 2.3729', '6.0294 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 243/3620', 'Training loss: 2.3713', '6.0686 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 244/3620', 'Training loss: 2.3699', '6.0397 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 245/3620', 'Training loss: 2.3682', '6.0386 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 246/3620', 'Training loss: 2.3672', '6.0590 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 247/3620', 'Training loss: 2.3664', '6.0360 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 248/3620', 'Training loss: 2.3649', '6.0913 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 249/3620', 'Training loss: 2.3636', '6.0330 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 250/3620', 'Training loss: 2.3616', '6.0584 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 251/3620', 'Training loss: 2.3604', '5.9446 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 252/3620', 'Training loss: 2.3589', '6.0447 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 253/3620', 'Training loss: 2.3572', '6.0866 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 254/3620', 'Training loss: 2.3558', '6.0173 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 255/3620', 'Training loss: 2.3548', '6.0306 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 256/3620', 'Training loss: 2.3535', '6.0748 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 257/3620', 'Training loss: 2.3520', '6.0967 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 258/3620', 'Training loss: 2.3506', '6.1204 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 259/3620', 'Training loss: 2.3494', '6.1227 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 260/3620', 'Training loss: 2.3480', '6.1016 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 261/3620', 'Training loss: 2.3471', '6.2103 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 262/3620', 'Training loss: 2.3457', '6.0974 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 263/3620', 'Training loss: 2.3442', '6.0998 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 264/3620', 'Training loss: 2.3429', '6.1139 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 265/3620', 'Training loss: 2.3418', '6.0783 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 266/3620', 'Training loss: 2.3402', '6.0626 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 267/3620', 'Training loss: 2.3388', '6.0232 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 268/3620', 'Training loss: 2.3371', '6.0364 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 269/3620', 'Training loss: 2.3357', '6.1000 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 270/3620', 'Training loss: 2.3344', '6.2918 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 271/3620', 'Training loss: 2.3331', '6.9016 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 272/3620', 'Training loss: 2.3316', '5.9163 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 273/3620', 'Training loss: 2.3303', '6.1710 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 274/3620', 'Training loss: 2.3288', '6.1167 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 275/3620', 'Training loss: 2.3277', '6.0663 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 276/3620', 'Training loss: 2.3265', '6.0546 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 277/3620', 'Training loss: 2.3252', '6.0643 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 278/3620', 'Training loss: 2.3240', '6.0489 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 279/3620', 'Training loss: 2.3227', '6.0405 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 280/3620', 'Training loss: 2.3210', '6.0323 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 281/3620', 'Training loss: 2.3198', '6.0691 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 282/3620', 'Training loss: 2.3183', '6.0629 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 283/3620', 'Training loss: 2.3170', '6.5037 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 284/3620', 'Training loss: 2.3155', '6.0653 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 285/3620', 'Training loss: 2.3141', '6.1083 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 286/3620', 'Training loss: 2.3133', '6.1059 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 287/3620', 'Training loss: 2.3120', '6.0013 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 288/3620', 'Training loss: 2.3106', '6.0907 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 289/3620', 'Training loss: 2.3095', '6.0290 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 290/3620', 'Training loss: 2.3082', '6.0162 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 291/3620', 'Training loss: 2.3071', '6.1893 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 292/3620', 'Training loss: 2.3059', '6.0110 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 293/3620', 'Training loss: 2.3050', '6.1542 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 294/3620', 'Training loss: 2.3040', '6.0560 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 295/3620', 'Training loss: 2.3029', '6.1066 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 296/3620', 'Training loss: 2.3020', '6.0591 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 297/3620', 'Training loss: 2.3007', '6.0915 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 298/3620', 'Training loss: 2.2995', '6.0919 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 299/3620', 'Training loss: 2.2983', '6.0716 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 300/3620', 'Training loss: 2.2970', '6.1116 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 301/3620', 'Training loss: 2.2958', '6.0706 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 302/3620', 'Training loss: 2.2947', '6.0809 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 303/3620', 'Training loss: 2.2937', '6.0755 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 304/3620', 'Training loss: 2.2924', '6.7187 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 305/3620', 'Training loss: 2.2914', '8.2604 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 306/3620', 'Training loss: 2.2904', '6.1826 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 307/3620', 'Training loss: 2.2893', '6.2072 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 308/3620', 'Training loss: 2.2879', '6.1935 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 309/3620', 'Training loss: 2.2868', '6.2536 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 310/3620', 'Training loss: 2.2857', '6.1940 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 311/3620', 'Training loss: 2.2847', '6.3333 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 312/3620', 'Training loss: 2.2836', '6.2751 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 313/3620', 'Training loss: 2.2827', '6.3152 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 314/3620', 'Training loss: 2.2817', '6.2512 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 315/3620', 'Training loss: 2.2806', '6.2458 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 316/3620', 'Training loss: 2.2793', '6.1267 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 317/3620', 'Training loss: 2.2783', '6.1090 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 318/3620', 'Training loss: 2.2771', '6.0617 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 319/3620', 'Training loss: 2.2762', '6.1745 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 320/3620', 'Training loss: 2.2753', '6.2718 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 321/3620', 'Training loss: 2.2741', '6.2768 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 322/3620', 'Training loss: 2.2730', '6.1869 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 323/3620', 'Training loss: 2.2722', '6.1112 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 324/3620', 'Training loss: 2.2712', '6.1371 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 325/3620', 'Training loss: 2.2701', '6.1392 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 326/3620', 'Training loss: 2.2691', '6.1474 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 327/3620', 'Training loss: 2.2680', '6.0957 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 328/3620', 'Training loss: 2.2670', '6.0653 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 329/3620', 'Training loss: 2.2660', '6.0784 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 330/3620', 'Training loss: 2.2650', '6.1754 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 331/3620', 'Training loss: 2.2640', '6.0986 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 332/3620', 'Training loss: 2.2631', '7.5894 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 333/3620', 'Training loss: 2.2622', '5.9432 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 334/3620', 'Training loss: 2.2615', '6.1385 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 335/3620', 'Training loss: 2.2605', '6.0749 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 336/3620', 'Training loss: 2.2595', '6.0853 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 337/3620', 'Training loss: 2.2586', '6.0727 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 338/3620', 'Training loss: 2.2577', '6.0913 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 339/3620', 'Training loss: 2.2570', '6.1058 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 340/3620', 'Training loss: 2.2559', '6.0915 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 341/3620', 'Training loss: 2.2550', '6.0802 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 342/3620', 'Training loss: 2.2541', '6.0627 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 343/3620', 'Training loss: 2.2532', '6.0910 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 344/3620', 'Training loss: 2.2521', '6.0778 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 345/3620', 'Training loss: 2.2511', '6.1231 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 346/3620', 'Training loss: 2.2502', '6.0836 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 347/3620', 'Training loss: 2.2491', '6.0855 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 348/3620', 'Training loss: 2.2483', '6.6728 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 349/3620', 'Training loss: 2.2474', '6.1429 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 350/3620', 'Training loss: 2.2464', '6.0796 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 351/3620', 'Training loss: 2.2456', '6.1056 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 352/3620', 'Training loss: 2.2447', '6.2243 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 353/3620', 'Training loss: 2.2440', '7.7324 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 354/3620', 'Training loss: 2.2432', '6.9598 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 355/3620', 'Training loss: 2.2421', '11.0715 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 356/3620', 'Training loss: 2.2411', '6.9088 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 357/3620', 'Training loss: 2.2401', '6.5193 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 358/3620', 'Training loss: 2.2392', '7.9138 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 359/3620', 'Training loss: 2.2385', '6.5552 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 360/3620', 'Training loss: 2.2377', '6.7726 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 361/3620', 'Training loss: 2.2370', '7.1011 sec/batch')\n",
      "('Epoch 2/20 ', 'Iteration 362/3620', 'Training loss: 2.2361', '6.9090 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 363/3620', 'Training loss: 2.1378', '7.1368 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 364/3620', 'Training loss: 2.0981', '6.3669 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 365/3620', 'Training loss: 2.0735', '6.8842 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 366/3620', 'Training loss: 2.0677', '7.7022 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 367/3620', 'Training loss: 2.0642', '6.4845 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 368/3620', 'Training loss: 2.0677', '6.2594 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 369/3620', 'Training loss: 2.0638', '6.9087 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 370/3620', 'Training loss: 2.0628', '6.8584 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 371/3620', 'Training loss: 2.0613', '6.8974 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 372/3620', 'Training loss: 2.0600', '6.3161 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 373/3620', 'Training loss: 2.0622', '6.3331 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 374/3620', 'Training loss: 2.0611', '9.7875 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 375/3620', 'Training loss: 2.0600', '11.0876 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 376/3620', 'Training loss: 2.0585', '8.6759 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 377/3620', 'Training loss: 2.0606', '7.0837 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 378/3620', 'Training loss: 2.0576', '6.5676 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 379/3620', 'Training loss: 2.0556', '6.9633 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 380/3620', 'Training loss: 2.0553', '6.9725 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 381/3620', 'Training loss: 2.0560', '6.7710 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 382/3620', 'Training loss: 2.0569', '10.6437 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 383/3620', 'Training loss: 2.0570', '7.2507 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 384/3620', 'Training loss: 2.0559', '9.7239 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 385/3620', 'Training loss: 2.0545', '7.7417 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 386/3620', 'Training loss: 2.0544', '8.1542 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 387/3620', 'Training loss: 2.0531', '6.7791 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 388/3620', 'Training loss: 2.0531', '7.2231 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 389/3620', 'Training loss: 2.0525', '7.3059 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 390/3620', 'Training loss: 2.0500', '9.7057 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 391/3620', 'Training loss: 2.0498', '6.7891 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 392/3620', 'Training loss: 2.0498', '7.7453 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 393/3620', 'Training loss: 2.0492', '7.6632 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 394/3620', 'Training loss: 2.0488', '8.1059 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 395/3620', 'Training loss: 2.0474', '6.9053 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 396/3620', 'Training loss: 2.0466', '7.7396 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 397/3620', 'Training loss: 2.0459', '7.2353 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 398/3620', 'Training loss: 2.0460', '6.8230 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 399/3620', 'Training loss: 2.0453', '7.5092 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 400/3620', 'Training loss: 2.0433', '6.9192 sec/batch')\n",
      "('Validation loss:', 1.914781, 'Saving checkpoint!')\n",
      "('Epoch 3/20 ', 'Iteration 401/3620', 'Training loss: 2.0431', '7.4157 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 402/3620', 'Training loss: 2.0415', '6.9121 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 403/3620', 'Training loss: 2.0393', '8.3149 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 404/3620', 'Training loss: 2.0380', '7.1321 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 405/3620', 'Training loss: 2.0368', '7.0643 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 406/3620', 'Training loss: 2.0355', '7.5882 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 407/3620', 'Training loss: 2.0348', '8.7540 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 408/3620', 'Training loss: 2.0335', '7.9650 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 409/3620', 'Training loss: 2.0322', '7.3541 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 410/3620', 'Training loss: 2.0306', '6.5813 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 411/3620', 'Training loss: 2.0301', '8.6893 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 412/3620', 'Training loss: 2.0293', '6.7748 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 413/3620', 'Training loss: 2.0288', '6.2556 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 414/3620', 'Training loss: 2.0279', '6.3575 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 415/3620', 'Training loss: 2.0277', '7.6545 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 416/3620', 'Training loss: 2.0267', '6.1032 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 417/3620', 'Training loss: 2.0261', '7.7877 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 418/3620', 'Training loss: 2.0255', '8.5814 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 419/3620', 'Training loss: 2.0247', '6.3754 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 420/3620', 'Training loss: 2.0241', '6.4825 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 421/3620', 'Training loss: 2.0234', '6.3240 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 422/3620', 'Training loss: 2.0229', '6.0706 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 423/3620', 'Training loss: 2.0226', '6.1209 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 424/3620', 'Training loss: 2.0217', '7.6904 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 425/3620', 'Training loss: 2.0211', '7.8831 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 426/3620', 'Training loss: 2.0202', '7.4548 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 427/3620', 'Training loss: 2.0202', '8.4540 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 428/3620', 'Training loss: 2.0203', '7.5417 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 429/3620', 'Training loss: 2.0196', '6.7917 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 430/3620', 'Training loss: 2.0191', '8.8767 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 431/3620', 'Training loss: 2.0180', '6.5076 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 432/3620', 'Training loss: 2.0175', '7.1007 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 433/3620', 'Training loss: 2.0168', '6.1032 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 434/3620', 'Training loss: 2.0160', '10.5362 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 435/3620', 'Training loss: 2.0153', '6.4562 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 436/3620', 'Training loss: 2.0150', '6.1096 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 437/3620', 'Training loss: 2.0147', '6.2964 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 438/3620', 'Training loss: 2.0141', '6.2619 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 439/3620', 'Training loss: 2.0134', '6.4134 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 440/3620', 'Training loss: 2.0128', '8.7496 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 441/3620', 'Training loss: 2.0120', '7.9113 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 442/3620', 'Training loss: 2.0116', '8.1933 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 443/3620', 'Training loss: 2.0107', '7.7207 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 444/3620', 'Training loss: 2.0098', '8.8679 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 445/3620', 'Training loss: 2.0091', '6.8782 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 446/3620', 'Training loss: 2.0087', '7.4697 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 447/3620', 'Training loss: 2.0077', '8.4541 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 448/3620', 'Training loss: 2.0066', '7.5537 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 449/3620', 'Training loss: 2.0055', '7.6301 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 450/3620', 'Training loss: 2.0048', '8.8758 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 451/3620', 'Training loss: 2.0039', '7.2705 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 452/3620', 'Training loss: 2.0032', '7.0408 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 453/3620', 'Training loss: 2.0022', '6.3259 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 454/3620', 'Training loss: 2.0011', '9.5565 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 455/3620', 'Training loss: 2.0002', '7.7505 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 456/3620', 'Training loss: 1.9994', '6.4943 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 457/3620', 'Training loss: 1.9987', '6.2253 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 458/3620', 'Training loss: 1.9980', '5.9287 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 459/3620', 'Training loss: 1.9974', '6.1505 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 460/3620', 'Training loss: 1.9968', '6.1329 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 461/3620', 'Training loss: 1.9958', '6.9164 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 462/3620', 'Training loss: 1.9951', '6.1083 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 463/3620', 'Training loss: 1.9941', '6.2760 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 464/3620', 'Training loss: 1.9932', '6.3635 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 465/3620', 'Training loss: 1.9922', '6.2917 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 466/3620', 'Training loss: 1.9913', '6.2549 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 467/3620', 'Training loss: 1.9910', '9.1824 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 468/3620', 'Training loss: 1.9903', '8.2883 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 469/3620', 'Training loss: 1.9895', '8.3801 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 470/3620', 'Training loss: 1.9891', '8.7341 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 471/3620', 'Training loss: 1.9882', '8.3949 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 472/3620', 'Training loss: 1.9877', '8.3921 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 473/3620', 'Training loss: 1.9870', '8.5907 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 474/3620', 'Training loss: 1.9867', '8.4588 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 475/3620', 'Training loss: 1.9862', '8.6991 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 476/3620', 'Training loss: 1.9857', '8.6466 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 477/3620', 'Training loss: 1.9851', '8.7017 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 478/3620', 'Training loss: 1.9842', '8.5391 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 479/3620', 'Training loss: 1.9835', '9.4945 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 480/3620', 'Training loss: 1.9828', '8.5410 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 481/3620', 'Training loss: 1.9821', '11.1400 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 482/3620', 'Training loss: 1.9814', '9.9820 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 483/3620', 'Training loss: 1.9807', '9.4679 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 484/3620', 'Training loss: 1.9801', '8.4843 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 485/3620', 'Training loss: 1.9792', '8.6445 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 486/3620', 'Training loss: 1.9788', '8.7025 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 487/3620', 'Training loss: 1.9781', '9.1704 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 488/3620', 'Training loss: 1.9774', '7.2438 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 489/3620', 'Training loss: 1.9765', '7.9123 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 490/3620', 'Training loss: 1.9760', '8.2967 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 491/3620', 'Training loss: 1.9753', '8.3639 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 492/3620', 'Training loss: 1.9748', '8.3634 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 493/3620', 'Training loss: 1.9742', '8.4541 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 494/3620', 'Training loss: 1.9736', '8.5983 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 495/3620', 'Training loss: 1.9731', '6.3259 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 496/3620', 'Training loss: 1.9724', '6.3248 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 497/3620', 'Training loss: 1.9717', '6.2676 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 498/3620', 'Training loss: 1.9711', '6.2867 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 499/3620', 'Training loss: 1.9704', '6.2837 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 500/3620', 'Training loss: 1.9700', '6.3196 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 501/3620', 'Training loss: 1.9695', '6.3723 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 502/3620', 'Training loss: 1.9689', '6.2301 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 503/3620', 'Training loss: 1.9683', '6.2462 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 504/3620', 'Training loss: 1.9679', '6.9010 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 505/3620', 'Training loss: 1.9674', '6.3737 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 506/3620', 'Training loss: 1.9670', '6.4620 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 507/3620', 'Training loss: 1.9664', '6.4313 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 508/3620', 'Training loss: 1.9659', '6.1141 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 509/3620', 'Training loss: 1.9654', '6.7814 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 510/3620', 'Training loss: 1.9648', '7.1929 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 511/3620', 'Training loss: 1.9644', '7.7694 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 512/3620', 'Training loss: 1.9638', '8.2263 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 513/3620', 'Training loss: 1.9634', '8.2568 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 514/3620', 'Training loss: 1.9630', '9.0169 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 515/3620', 'Training loss: 1.9627', '8.5964 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 516/3620', 'Training loss: 1.9622', '8.5380 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 517/3620', 'Training loss: 1.9616', '8.5820 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 518/3620', 'Training loss: 1.9612', '8.5043 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 519/3620', 'Training loss: 1.9606', '8.4618 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 520/3620', 'Training loss: 1.9604', '8.6229 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 521/3620', 'Training loss: 1.9597', '8.4540 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 522/3620', 'Training loss: 1.9593', '8.5894 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 523/3620', 'Training loss: 1.9588', '8.6023 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 524/3620', 'Training loss: 1.9584', '8.4815 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 525/3620', 'Training loss: 1.9577', '9.5179 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 526/3620', 'Training loss: 1.9571', '8.9319 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 527/3620', 'Training loss: 1.9566', '8.5826 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 528/3620', 'Training loss: 1.9561', '8.6621 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 529/3620', 'Training loss: 1.9557', '8.6051 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 530/3620', 'Training loss: 1.9552', '8.6121 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 531/3620', 'Training loss: 1.9547', '8.5065 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 532/3620', 'Training loss: 1.9544', '6.7926 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 533/3620', 'Training loss: 1.9539', '8.6640 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 534/3620', 'Training loss: 1.9536', '8.4640 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 535/3620', 'Training loss: 1.9532', '8.4805 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 536/3620', 'Training loss: 1.9525', '9.3074 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 537/3620', 'Training loss: 1.9520', '8.2814 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 538/3620', 'Training loss: 1.9513', '7.0711 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 539/3620', 'Training loss: 1.9507', '6.1634 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 540/3620', 'Training loss: 1.9503', '6.2788 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 541/3620', 'Training loss: 1.9498', '6.4773 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 542/3620', 'Training loss: 1.9494', '6.5249 sec/batch')\n",
      "('Epoch 3/20 ', 'Iteration 543/3620', 'Training loss: 1.9489', '6.2974 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 544/3620', 'Training loss: 1.9300', '6.1791 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 545/3620', 'Training loss: 1.8894', '6.4683 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 546/3620', 'Training loss: 1.8709', '7.1158 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 547/3620', 'Training loss: 1.8643', '7.3136 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 548/3620', 'Training loss: 1.8625', '8.6188 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 549/3620', 'Training loss: 1.8649', '11.5121 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 550/3620', 'Training loss: 1.8579', '10.8427 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 551/3620', 'Training loss: 1.8551', '8.7453 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 552/3620', 'Training loss: 1.8528', '8.7936 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 553/3620', 'Training loss: 1.8503', '7.4744 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 554/3620', 'Training loss: 1.8527', '7.1858 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 555/3620', 'Training loss: 1.8512', '7.3645 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 556/3620', 'Training loss: 1.8500', '7.2216 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 557/3620', 'Training loss: 1.8486', '7.2017 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 558/3620', 'Training loss: 1.8515', '7.4375 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 559/3620', 'Training loss: 1.8477', '7.6321 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 560/3620', 'Training loss: 1.8473', '7.3818 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 561/3620', 'Training loss: 1.8468', '8.5593 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 562/3620', 'Training loss: 1.8464', '7.3766 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 563/3620', 'Training loss: 1.8481', '7.6270 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 564/3620', 'Training loss: 1.8484', '7.5199 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 565/3620', 'Training loss: 1.8472', '7.4622 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 566/3620', 'Training loss: 1.8462', '7.3720 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 567/3620', 'Training loss: 1.8462', '7.6164 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 568/3620', 'Training loss: 1.8454', '7.3268 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 569/3620', 'Training loss: 1.8452', '7.5169 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 570/3620', 'Training loss: 1.8451', '7.4484 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 571/3620', 'Training loss: 1.8427', '7.6783 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 572/3620', 'Training loss: 1.8422', '7.4203 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 573/3620', 'Training loss: 1.8419', '7.4771 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 574/3620', 'Training loss: 1.8415', '8.0274 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 575/3620', 'Training loss: 1.8415', '7.5405 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 576/3620', 'Training loss: 1.8409', '8.3470 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 577/3620', 'Training loss: 1.8405', '7.5983 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 578/3620', 'Training loss: 1.8405', '7.9857 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 579/3620', 'Training loss: 1.8410', '7.6685 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 580/3620', 'Training loss: 1.8405', '7.7996 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 581/3620', 'Training loss: 1.8389', '8.4232 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 582/3620', 'Training loss: 1.8378', '7.9576 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 583/3620', 'Training loss: 1.8370', '7.7654 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 584/3620', 'Training loss: 1.8352', '7.9081 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 585/3620', 'Training loss: 1.8345', '7.7650 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 586/3620', 'Training loss: 1.8335', '7.8933 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 587/3620', 'Training loss: 1.8325', '8.1833 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 588/3620', 'Training loss: 1.8322', '7.9275 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 589/3620', 'Training loss: 1.8314', '8.4114 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 590/3620', 'Training loss: 1.8304', '8.0859 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 591/3620', 'Training loss: 1.8291', '8.0866 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 592/3620', 'Training loss: 1.8288', '8.0010 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 593/3620', 'Training loss: 1.8284', '7.9404 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 594/3620', 'Training loss: 1.8280', '8.1167 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 595/3620', 'Training loss: 1.8274', '8.0486 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 596/3620', 'Training loss: 1.8273', '7.9722 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 597/3620', 'Training loss: 1.8265', '8.9525 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 598/3620', 'Training loss: 1.8261', '8.0322 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 599/3620', 'Training loss: 1.8261', '8.3063 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 600/3620', 'Training loss: 1.8256', '7.9999 sec/batch')\n",
      "('Validation loss:', 1.6916831, 'Saving checkpoint!')\n",
      "('Epoch 4/20 ', 'Iteration 601/3620', 'Training loss: 1.8260', '9.5342 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 602/3620', 'Training loss: 1.8255', '8.5979 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 603/3620', 'Training loss: 1.8252', '8.5383 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 604/3620', 'Training loss: 1.8252', '7.9055 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 605/3620', 'Training loss: 1.8247', '6.3709 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 606/3620', 'Training loss: 1.8245', '6.3188 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 607/3620', 'Training loss: 1.8241', '7.1609 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 608/3620', 'Training loss: 1.8245', '6.2775 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 609/3620', 'Training loss: 1.8250', '6.2236 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 610/3620', 'Training loss: 1.8244', '6.2383 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 611/3620', 'Training loss: 1.8244', '6.2245 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 612/3620', 'Training loss: 1.8237', '6.4707 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 613/3620', 'Training loss: 1.8235', '6.4550 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 614/3620', 'Training loss: 1.8231', '6.2940 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 615/3620', 'Training loss: 1.8226', '6.4105 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 616/3620', 'Training loss: 1.8222', '6.3089 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 617/3620', 'Training loss: 1.8223', '6.3128 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 618/3620', 'Training loss: 1.8223', '6.4439 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 619/3620', 'Training loss: 1.8219', '6.3332 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 620/3620', 'Training loss: 1.8215', '6.4553 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 621/3620', 'Training loss: 1.8211', '7.4992 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 622/3620', 'Training loss: 1.8204', '6.1531 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 623/3620', 'Training loss: 1.8202', '6.4481 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 624/3620', 'Training loss: 1.8197', '7.6784 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 625/3620', 'Training loss: 1.8191', '6.1088 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 626/3620', 'Training loss: 1.8187', '6.1435 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 627/3620', 'Training loss: 1.8181', '6.1734 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 628/3620', 'Training loss: 1.8174', '6.4075 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 629/3620', 'Training loss: 1.8165', '6.1808 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 630/3620', 'Training loss: 1.8157', '6.2439 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 631/3620', 'Training loss: 1.8152', '6.3403 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 632/3620', 'Training loss: 1.8147', '6.3876 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 633/3620', 'Training loss: 1.8143', '6.3304 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 634/3620', 'Training loss: 1.8135', '6.4846 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 635/3620', 'Training loss: 1.8126', '6.1832 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 636/3620', 'Training loss: 1.8122', '7.6647 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 637/3620', 'Training loss: 1.8116', '6.2711 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 638/3620', 'Training loss: 1.8113', '6.1669 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 639/3620', 'Training loss: 1.8107', '6.3023 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 640/3620', 'Training loss: 1.8104', '6.2816 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 641/3620', 'Training loss: 1.8101', '6.3114 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 642/3620', 'Training loss: 1.8093', '6.1754 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 643/3620', 'Training loss: 1.8090', '6.3554 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 644/3620', 'Training loss: 1.8082', '6.3316 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 645/3620', 'Training loss: 1.8074', '6.4179 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 646/3620', 'Training loss: 1.8066', '6.3182 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 647/3620', 'Training loss: 1.8058', '6.3131 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 648/3620', 'Training loss: 1.8055', '6.2816 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 649/3620', 'Training loss: 1.8050', '6.3464 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 650/3620', 'Training loss: 1.8043', '6.2766 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 651/3620', 'Training loss: 1.8039', '6.3300 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 652/3620', 'Training loss: 1.8033', '7.1550 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 653/3620', 'Training loss: 1.8027', '6.0998 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 654/3620', 'Training loss: 1.8022', '6.4213 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 655/3620', 'Training loss: 1.8021', '6.3477 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 656/3620', 'Training loss: 1.8019', '6.3438 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 657/3620', 'Training loss: 1.8016', '2549.3040 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 658/3620', 'Training loss: 1.8011', '10.2986 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 659/3620', 'Training loss: 1.8003', '8.8500 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 660/3620', 'Training loss: 1.7998', '7.1432 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 661/3620', 'Training loss: 1.7993', '9.5977 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 662/3620', 'Training loss: 1.7988', '7.9808 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 663/3620', 'Training loss: 1.7982', '9.3752 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 664/3620', 'Training loss: 1.7976', '7.8392 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 665/3620', 'Training loss: 1.7972', '14.7251 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 666/3620', 'Training loss: 1.7966', '12.1551 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 667/3620', 'Training loss: 1.7964', '9.4751 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 668/3620', 'Training loss: 1.7958', '7.6031 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 669/3620', 'Training loss: 1.7952', '6.7246 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 670/3620', 'Training loss: 1.7945', '6.7633 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 671/3620', 'Training loss: 1.7943', '7.3040 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 672/3620', 'Training loss: 1.7938', '7.1606 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 673/3620', 'Training loss: 1.7934', '7.1199 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 674/3620', 'Training loss: 1.7929', '7.0675 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 675/3620', 'Training loss: 1.7926', '7.9109 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 676/3620', 'Training loss: 1.7923', '6.9801 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 677/3620', 'Training loss: 1.7918', '7.6673 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 678/3620', 'Training loss: 1.7913', '6.4034 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 679/3620', 'Training loss: 1.7910', '6.4811 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 680/3620', 'Training loss: 1.7904', '6.5655 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 681/3620', 'Training loss: 1.7901', '6.5488 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 682/3620', 'Training loss: 1.7898', '6.3309 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 683/3620', 'Training loss: 1.7894', '6.4976 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 684/3620', 'Training loss: 1.7890', '6.6221 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 685/3620', 'Training loss: 1.7888', '6.3130 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 686/3620', 'Training loss: 1.7884', '6.6056 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 687/3620', 'Training loss: 1.7881', '6.8392 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 688/3620', 'Training loss: 1.7878', '6.9193 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 689/3620', 'Training loss: 1.7873', '6.7876 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 690/3620', 'Training loss: 1.7870', '6.5993 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 691/3620', 'Training loss: 1.7866', '7.2641 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 692/3620', 'Training loss: 1.7864', '6.9064 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 693/3620', 'Training loss: 1.7859', '6.7000 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 694/3620', 'Training loss: 1.7857', '6.9697 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 695/3620', 'Training loss: 1.7855', '7.1049 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 696/3620', 'Training loss: 1.7854', '7.6800 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 697/3620', 'Training loss: 1.7851', '6.5667 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 698/3620', 'Training loss: 1.7847', '6.8954 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 699/3620', 'Training loss: 1.7844', '7.6296 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 700/3620', 'Training loss: 1.7839', '6.5900 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 701/3620', 'Training loss: 1.7837', '6.6074 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 702/3620', 'Training loss: 1.7833', '6.7393 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 703/3620', 'Training loss: 1.7830', '6.5946 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 704/3620', 'Training loss: 1.7828', '6.9098 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 705/3620', 'Training loss: 1.7825', '7.2008 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 706/3620', 'Training loss: 1.7819', '6.4292 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 707/3620', 'Training loss: 1.7815', '6.6892 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 708/3620', 'Training loss: 1.7811', '6.7461 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 709/3620', 'Training loss: 1.7808', '7.8457 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 710/3620', 'Training loss: 1.7806', '7.2253 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 711/3620', 'Training loss: 1.7803', '6.8299 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 712/3620', 'Training loss: 1.7799', '6.9209 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 713/3620', 'Training loss: 1.7797', '7.0798 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 714/3620', 'Training loss: 1.7794', '7.1110 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 715/3620', 'Training loss: 1.7794', '6.8649 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 716/3620', 'Training loss: 1.7792', '6.9407 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 717/3620', 'Training loss: 1.7788', '7.3929 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 718/3620', 'Training loss: 1.7784', '7.4995 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 719/3620', 'Training loss: 1.7780', '7.0025 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 720/3620', 'Training loss: 1.7775', '6.8967 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 721/3620', 'Training loss: 1.7774', '7.1852 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 722/3620', 'Training loss: 1.7771', '6.8745 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 723/3620', 'Training loss: 1.7769', '6.7534 sec/batch')\n",
      "('Epoch 4/20 ', 'Iteration 724/3620', 'Training loss: 1.7765', '6.7201 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 725/3620', 'Training loss: 1.7955', '7.4074 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 726/3620', 'Training loss: 1.7542', '6.5651 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 727/3620', 'Training loss: 1.7375', '6.8799 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 728/3620', 'Training loss: 1.7327', '7.0294 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 729/3620', 'Training loss: 1.7268', '6.8497 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 730/3620', 'Training loss: 1.7273', '6.6366 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 731/3620', 'Training loss: 1.7191', '6.9178 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 732/3620', 'Training loss: 1.7165', '6.7101 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 733/3620', 'Training loss: 1.7131', '6.8413 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 734/3620', 'Training loss: 1.7094', '7.0133 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 735/3620', 'Training loss: 1.7111', '6.6462 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 736/3620', 'Training loss: 1.7088', '6.7671 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 737/3620', 'Training loss: 1.7078', '7.0485 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 738/3620', 'Training loss: 1.7064', '6.6318 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 739/3620', 'Training loss: 1.7107', '6.4225 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 740/3620', 'Training loss: 1.7087', '6.9769 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 741/3620', 'Training loss: 1.7079', '6.3502 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 742/3620', 'Training loss: 1.7087', '6.8532 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 743/3620', 'Training loss: 1.7089', '6.8013 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 744/3620', 'Training loss: 1.7107', '6.3859 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 745/3620', 'Training loss: 1.7108', '6.4462 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 746/3620', 'Training loss: 1.7101', '6.6762 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 747/3620', 'Training loss: 1.7097', '6.7489 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 748/3620', 'Training loss: 1.7098', '6.8464 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 749/3620', 'Training loss: 1.7090', '6.5306 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 750/3620', 'Training loss: 1.7090', '6.4709 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 751/3620', 'Training loss: 1.7089', '6.5555 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 752/3620', 'Training loss: 1.7068', '6.6323 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 753/3620', 'Training loss: 1.7068', '6.5967 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 754/3620', 'Training loss: 1.7067', '6.8295 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 755/3620', 'Training loss: 1.7068', '6.6708 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 756/3620', 'Training loss: 1.7071', '6.5695 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 757/3620', 'Training loss: 1.7066', '6.5472 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 758/3620', 'Training loss: 1.7065', '6.9725 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 759/3620', 'Training loss: 1.7064', '6.7477 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 760/3620', 'Training loss: 1.7068', '6.5314 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 761/3620', 'Training loss: 1.7064', '6.4503 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 762/3620', 'Training loss: 1.7048', '6.6238 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 763/3620', 'Training loss: 1.7042', '6.5914 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 764/3620', 'Training loss: 1.7030', '6.5333 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 765/3620', 'Training loss: 1.7015', '6.6325 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 766/3620', 'Training loss: 1.7011', '6.5296 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 767/3620', 'Training loss: 1.7002', '7.0931 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 768/3620', 'Training loss: 1.6994', '6.7048 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 769/3620', 'Training loss: 1.6992', '6.8631 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 770/3620', 'Training loss: 1.6985', '6.9095 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 771/3620', 'Training loss: 1.6977', '6.3100 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 772/3620', 'Training loss: 1.6965', '6.9827 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 773/3620', 'Training loss: 1.6963', '6.3186 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 774/3620', 'Training loss: 1.6959', '6.6417 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 775/3620', 'Training loss: 1.6956', '6.7845 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 776/3620', 'Training loss: 1.6949', '6.4519 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 777/3620', 'Training loss: 1.6950', '6.4326 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 778/3620', 'Training loss: 1.6945', '6.4413 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 779/3620', 'Training loss: 1.6943', '6.5191 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 780/3620', 'Training loss: 1.6945', '6.7597 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 781/3620', 'Training loss: 1.6942', '6.6492 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 782/3620', 'Training loss: 1.6938', '6.7770 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 783/3620', 'Training loss: 1.6935', '6.6787 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 784/3620', 'Training loss: 1.6933', '6.9497 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 785/3620', 'Training loss: 1.6935', '6.9586 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 786/3620', 'Training loss: 1.6929', '6.4885 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 787/3620', 'Training loss: 1.6927', '7.7426 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 788/3620', 'Training loss: 1.6926', '6.8088 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 789/3620', 'Training loss: 1.6929', '6.8579 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 790/3620', 'Training loss: 1.6935', '6.9040 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 791/3620', 'Training loss: 1.6929', '6.6678 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 792/3620', 'Training loss: 1.6930', '7.0073 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 793/3620', 'Training loss: 1.6922', '6.4613 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 794/3620', 'Training loss: 1.6921', '6.4109 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 795/3620', 'Training loss: 1.6918', '6.3029 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 796/3620', 'Training loss: 1.6914', '6.3039 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 797/3620', 'Training loss: 1.6912', '6.2964 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 798/3620', 'Training loss: 1.6913', '6.4345 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 799/3620', 'Training loss: 1.6912', '6.3253 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 800/3620', 'Training loss: 1.6908', '6.2936 sec/batch')\n",
      "('Validation loss:', 1.5514274, 'Saving checkpoint!')\n",
      "('Epoch 5/20 ', 'Iteration 801/3620', 'Training loss: 1.6914', '7.3421 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 802/3620', 'Training loss: 1.6908', '6.3549 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 803/3620', 'Training loss: 1.6901', '6.3877 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 804/3620', 'Training loss: 1.6900', '6.4152 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 805/3620', 'Training loss: 1.6898', '6.8265 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 806/3620', 'Training loss: 1.6893', '6.6998 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 807/3620', 'Training loss: 1.6889', '6.5491 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 808/3620', 'Training loss: 1.6884', '6.3739 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 809/3620', 'Training loss: 1.6878', '6.7623 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 810/3620', 'Training loss: 1.6869', '6.2306 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 811/3620', 'Training loss: 1.6862', '6.3332 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 812/3620', 'Training loss: 1.6859', '6.7218 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 813/3620', 'Training loss: 1.6855', '7.0457 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 814/3620', 'Training loss: 1.6850', '6.3935 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 815/3620', 'Training loss: 1.6844', '6.8608 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 816/3620', 'Training loss: 1.6834', '6.3720 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 817/3620', 'Training loss: 1.6830', '6.2864 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 818/3620', 'Training loss: 1.6825', '6.7569 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 819/3620', 'Training loss: 1.6821', '6.7630 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 820/3620', 'Training loss: 1.6816', '6.5755 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 821/3620', 'Training loss: 1.6812', '6.2593 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 822/3620', 'Training loss: 1.6808', '6.5232 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 823/3620', 'Training loss: 1.6801', '7.1650 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 824/3620', 'Training loss: 1.6799', '7.1505 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 825/3620', 'Training loss: 1.6790', '6.5374 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 826/3620', 'Training loss: 1.6783', '6.3251 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 827/3620', 'Training loss: 1.6774', '6.3842 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 828/3620', 'Training loss: 1.6766', '6.3493 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 829/3620', 'Training loss: 1.6765', '6.5086 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 830/3620', 'Training loss: 1.6759', '6.5287 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 831/3620', 'Training loss: 1.6754', '6.6669 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 832/3620', 'Training loss: 1.6751', '6.2193 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 833/3620', 'Training loss: 1.6745', '6.5873 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 834/3620', 'Training loss: 1.6739', '6.3507 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 835/3620', 'Training loss: 1.6734', '6.8814 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 836/3620', 'Training loss: 1.6732', '6.6745 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 837/3620', 'Training loss: 1.6731', '8.3134 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 838/3620', 'Training loss: 1.6728', '6.2609 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 839/3620', 'Training loss: 1.6723', '6.4021 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 840/3620', 'Training loss: 1.6715', '6.6825 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 841/3620', 'Training loss: 1.6711', '6.9132 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 842/3620', 'Training loss: 1.6706', '6.9819 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 843/3620', 'Training loss: 1.6702', '6.9697 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 844/3620', 'Training loss: 1.6698', '6.5937 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 845/3620', 'Training loss: 1.6693', '7.2365 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 846/3620', 'Training loss: 1.6689', '6.7382 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 847/3620', 'Training loss: 1.6683', '6.7059 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 848/3620', 'Training loss: 1.6682', '6.9798 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 849/3620', 'Training loss: 1.6675', '6.4484 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 850/3620', 'Training loss: 1.6670', '6.7000 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 851/3620', 'Training loss: 1.6663', '7.1057 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 852/3620', 'Training loss: 1.6659', '7.2866 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 853/3620', 'Training loss: 1.6655', '6.7219 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 854/3620', 'Training loss: 1.6651', '6.7619 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 855/3620', 'Training loss: 1.6647', '7.2782 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 856/3620', 'Training loss: 1.6644', '6.7317 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 857/3620', 'Training loss: 1.6640', '6.4679 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 858/3620', 'Training loss: 1.6634', '6.1791 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 859/3620', 'Training loss: 1.6628', '6.8878 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 860/3620', 'Training loss: 1.6625', '7.2050 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 861/3620', 'Training loss: 1.6619', '7.0336 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 862/3620', 'Training loss: 1.6617', '7.2474 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 863/3620', 'Training loss: 1.6616', '6.5414 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 864/3620', 'Training loss: 1.6611', '6.8342 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 865/3620', 'Training loss: 1.6609', '6.9963 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 866/3620', 'Training loss: 1.6606', '7.0691 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 867/3620', 'Training loss: 1.6603', '6.7304 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 868/3620', 'Training loss: 1.6601', '7.3696 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 869/3620', 'Training loss: 1.6599', '6.2975 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 870/3620', 'Training loss: 1.6594', '6.3538 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 871/3620', 'Training loss: 1.6591', '7.0801 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 872/3620', 'Training loss: 1.6588', '6.8281 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 873/3620', 'Training loss: 1.6587', '8.0055 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 874/3620', 'Training loss: 1.6582', '6.9082 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 875/3620', 'Training loss: 1.6580', '6.6959 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 876/3620', 'Training loss: 1.6578', '7.1948 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 877/3620', 'Training loss: 1.6577', '6.3841 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 878/3620', 'Training loss: 1.6574', '7.2038 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 879/3620', 'Training loss: 1.6569', '6.5914 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 880/3620', 'Training loss: 1.6566', '6.9205 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 881/3620', 'Training loss: 1.6561', '6.3213 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 882/3620', 'Training loss: 1.6559', '6.2226 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 883/3620', 'Training loss: 1.6555', '6.0951 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 884/3620', 'Training loss: 1.6552', '242.2985 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 885/3620', 'Training loss: 1.6550', '9.9640 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 886/3620', 'Training loss: 1.6546', '6.4943 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 887/3620', 'Training loss: 1.6542', '6.7435 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 888/3620', 'Training loss: 1.6537', '6.5442 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 889/3620', 'Training loss: 1.6533', '6.8214 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 890/3620', 'Training loss: 1.6531', '6.3688 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 891/3620', 'Training loss: 1.6529', '7.4837 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 892/3620', 'Training loss: 1.6526', '6.3426 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 893/3620', 'Training loss: 1.6522', '6.1943 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 894/3620', 'Training loss: 1.6521', '6.1967 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 895/3620', 'Training loss: 1.6519', '6.1354 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 896/3620', 'Training loss: 1.6519', '6.1519 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 897/3620', 'Training loss: 1.6516', '6.0790 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 898/3620', 'Training loss: 1.6513', '6.0464 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 899/3620', 'Training loss: 1.6510', '6.0615 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 900/3620', 'Training loss: 1.6505', '6.0411 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 901/3620', 'Training loss: 1.6501', '6.0756 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 902/3620', 'Training loss: 1.6499', '6.0794 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 903/3620', 'Training loss: 1.6496', '6.3452 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 904/3620', 'Training loss: 1.6494', '6.2355 sec/batch')\n",
      "('Epoch 5/20 ', 'Iteration 905/3620', 'Training loss: 1.6490', '6.1158 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 906/3620', 'Training loss: 1.7208', '6.1044 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 907/3620', 'Training loss: 1.6614', '6.0724 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 908/3620', 'Training loss: 1.6385', '6.0785 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 909/3620', 'Training loss: 1.6306', '6.0774 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 910/3620', 'Training loss: 1.6255', '6.0318 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 911/3620', 'Training loss: 1.6244', '6.0517 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 912/3620', 'Training loss: 1.6161', '6.0919 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 913/3620', 'Training loss: 1.6122', '6.8414 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 914/3620', 'Training loss: 1.6094', '6.1466 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 915/3620', 'Training loss: 1.6054', '6.2210 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 916/3620', 'Training loss: 1.6073', '6.1378 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 917/3620', 'Training loss: 1.6049', '6.0640 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 918/3620', 'Training loss: 1.6037', '6.1040 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 919/3620', 'Training loss: 1.6027', '6.1216 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 920/3620', 'Training loss: 1.6054', '6.6847 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 921/3620', 'Training loss: 1.6019', '6.1276 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 922/3620', 'Training loss: 1.6002', '240.1648 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 923/3620', 'Training loss: 1.5999', '9.1560 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 924/3620', 'Training loss: 1.5994', '8.4832 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 925/3620', 'Training loss: 1.6009', '6.6348 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 926/3620', 'Training loss: 1.6003', '7.1237 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 927/3620', 'Training loss: 1.5998', '6.9700 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 928/3620', 'Training loss: 1.5994', '8.7874 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 929/3620', 'Training loss: 1.5991', '7.3715 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 930/3620', 'Training loss: 1.5983', '9.9348 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 931/3620', 'Training loss: 1.5982', '11.1964 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 932/3620', 'Training loss: 1.5982', '10.8946 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 933/3620', 'Training loss: 1.5958', '12.0665 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 934/3620', 'Training loss: 1.5955', '9.3597 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 935/3620', 'Training loss: 1.5953', '8.5581 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 936/3620', 'Training loss: 1.5952', '9.3150 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 937/3620', 'Training loss: 1.5952', '7.4188 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 938/3620', 'Training loss: 1.5949', '6.6271 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 939/3620', 'Training loss: 1.5941', '6.4977 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 940/3620', 'Training loss: 1.5940', '6.2919 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 941/3620', 'Training loss: 1.5949', '6.4740 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 942/3620', 'Training loss: 1.5946', '6.4321 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 943/3620', 'Training loss: 1.5930', '6.7905 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 944/3620', 'Training loss: 1.5920', '6.7935 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 945/3620', 'Training loss: 1.5906', '6.5904 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 946/3620', 'Training loss: 1.5894', '6.6429 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 947/3620', 'Training loss: 1.5887', '6.6888 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 948/3620', 'Training loss: 1.5878', '7.1107 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 949/3620', 'Training loss: 1.5869', '6.8144 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 950/3620', 'Training loss: 1.5868', '6.6169 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 951/3620', 'Training loss: 1.5861', '6.6829 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 952/3620', 'Training loss: 1.5852', '7.0093 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 953/3620', 'Training loss: 1.5843', '6.5906 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 954/3620', 'Training loss: 1.5843', '7.4023 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 955/3620', 'Training loss: 1.5838', '6.7132 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 956/3620', 'Training loss: 1.5832', '7.3525 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 957/3620', 'Training loss: 1.5825', '8.0678 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 958/3620', 'Training loss: 1.5825', '7.0219 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 959/3620', 'Training loss: 1.5820', '6.4855 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 960/3620', 'Training loss: 1.5816', '6.3921 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 961/3620', 'Training loss: 1.5815', '7.0812 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 962/3620', 'Training loss: 1.5809', '8.4926 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 963/3620', 'Training loss: 1.5807', '7.3472 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 964/3620', 'Training loss: 1.5802', '7.4621 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 965/3620', 'Training loss: 1.5798', '8.2103 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 966/3620', 'Training loss: 1.5799', '6.6000 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 967/3620', 'Training loss: 1.5793', '6.2908 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 968/3620', 'Training loss: 1.5792', '6.2658 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 969/3620', 'Training loss: 1.5789', '6.7746 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 970/3620', 'Training loss: 1.5795', '6.5189 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 971/3620', 'Training loss: 1.5801', '6.6049 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 972/3620', 'Training loss: 1.5794', '6.8176 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 973/3620', 'Training loss: 1.5795', '6.7381 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 974/3620', 'Training loss: 1.5787', '7.0128 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 975/3620', 'Training loss: 1.5785', '6.2238 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 976/3620', 'Training loss: 1.5782', '6.5318 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 977/3620', 'Training loss: 1.5780', '6.5908 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 978/3620', 'Training loss: 1.5779', '7.0933 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 979/3620', 'Training loss: 1.5782', '6.7146 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 980/3620', 'Training loss: 1.5782', '6.9575 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 981/3620', 'Training loss: 1.5779', '6.7218 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 982/3620', 'Training loss: 1.5778', '7.2177 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 983/3620', 'Training loss: 1.5774', '6.6699 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 984/3620', 'Training loss: 1.5767', '6.5912 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 985/3620', 'Training loss: 1.5767', '6.4348 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 986/3620', 'Training loss: 1.5767', '7.2124 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 987/3620', 'Training loss: 1.5764', '6.7890 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 988/3620', 'Training loss: 1.5762', '6.6967 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 989/3620', 'Training loss: 1.5756', '6.4321 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 990/3620', 'Training loss: 1.5752', '6.3595 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 991/3620', 'Training loss: 1.5745', '7.1373 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 992/3620', 'Training loss: 1.5737', '6.6086 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 993/3620', 'Training loss: 1.5735', '7.0872 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 994/3620', 'Training loss: 1.5731', '7.0411 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 995/3620', 'Training loss: 1.5727', '6.6336 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 996/3620', 'Training loss: 1.5722', '6.2219 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 997/3620', 'Training loss: 1.5713', '6.6346 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 998/3620', 'Training loss: 1.5711', '6.4025 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 999/3620', 'Training loss: 1.5707', '6.9961 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1000/3620', 'Training loss: 1.5704', '6.4077 sec/batch')\n",
      "('Validation loss:', 1.427406, 'Saving checkpoint!')\n",
      "('Epoch 6/20 ', 'Iteration 1001/3620', 'Training loss: 1.5713', '8.0994 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1002/3620', 'Training loss: 1.5710', '6.7541 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1003/3620', 'Training loss: 1.5707', '6.9557 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1004/3620', 'Training loss: 1.5702', '6.4925 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1005/3620', 'Training loss: 1.5699', '6.4305 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1006/3620', 'Training loss: 1.5692', '6.6641 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1007/3620', 'Training loss: 1.5685', '7.2458 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1008/3620', 'Training loss: 1.5678', '8.0367 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1009/3620', 'Training loss: 1.5673', '7.1684 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1010/3620', 'Training loss: 1.5672', '7.0537 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1011/3620', 'Training loss: 1.5666', '6.6964 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1012/3620', 'Training loss: 1.5662', '6.9132 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1013/3620', 'Training loss: 1.5661', '6.5393 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1014/3620', 'Training loss: 1.5655', '6.5844 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1015/3620', 'Training loss: 1.5651', '6.9750 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1016/3620', 'Training loss: 1.5646', '7.0304 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1017/3620', 'Training loss: 1.5646', '7.1296 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1018/3620', 'Training loss: 1.5644', '6.8531 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1019/3620', 'Training loss: 1.5641', '6.7143 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1020/3620', 'Training loss: 1.5637', '7.5340 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1021/3620', 'Training loss: 1.5631', '8.3481 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1022/3620', 'Training loss: 1.5628', '6.7404 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1023/3620', 'Training loss: 1.5624', '6.7962 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1024/3620', 'Training loss: 1.5620', '6.9200 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1025/3620', 'Training loss: 1.5615', '7.9524 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1026/3620', 'Training loss: 1.5611', '6.8245 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1027/3620', 'Training loss: 1.5609', '6.9842 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1028/3620', 'Training loss: 1.5606', '6.5459 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1029/3620', 'Training loss: 1.5605', '7.0622 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1030/3620', 'Training loss: 1.5600', '7.7906 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1031/3620', 'Training loss: 1.5595', '7.1697 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1032/3620', 'Training loss: 1.5589', '7.1908 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1033/3620', 'Training loss: 1.5587', '6.9598 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1034/3620', 'Training loss: 1.5584', '7.1131 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1035/3620', 'Training loss: 1.5582', '6.5085 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1036/3620', 'Training loss: 1.5579', '6.8698 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1037/3620', 'Training loss: 1.5575', '6.7210 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1038/3620', 'Training loss: 1.5572', '7.3898 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1039/3620', 'Training loss: 1.5567', '7.0210 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1040/3620', 'Training loss: 1.5564', '7.1169 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1041/3620', 'Training loss: 1.5563', '6.8598 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1042/3620', 'Training loss: 1.5559', '6.6640 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1043/3620', 'Training loss: 1.5558', '6.5707 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1044/3620', 'Training loss: 1.5557', '6.6103 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1045/3620', 'Training loss: 1.5554', '6.5944 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1046/3620', 'Training loss: 1.5552', '6.4976 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1047/3620', 'Training loss: 1.5550', '6.6420 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1048/3620', 'Training loss: 1.5548', '6.5412 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1049/3620', 'Training loss: 1.5548', '6.5854 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1050/3620', 'Training loss: 1.5547', '7.6673 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1051/3620', 'Training loss: 1.5544', '6.8720 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1052/3620', 'Training loss: 1.5542', '6.5995 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1053/3620', 'Training loss: 1.5540', '6.9660 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1054/3620', 'Training loss: 1.5540', '6.5059 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1055/3620', 'Training loss: 1.5537', '6.4576 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1056/3620', 'Training loss: 1.5536', '6.5936 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1057/3620', 'Training loss: 1.5535', '6.7030 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1058/3620', 'Training loss: 1.5535', '6.7133 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1059/3620', 'Training loss: 1.5533', '6.9702 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1060/3620', 'Training loss: 1.5528', '7.1525 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1061/3620', 'Training loss: 1.5527', '7.1606 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1062/3620', 'Training loss: 1.5523', '6.9793 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1063/3620', 'Training loss: 1.5522', '6.7547 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1064/3620', 'Training loss: 1.5520', '6.4528 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1065/3620', 'Training loss: 1.5519', '6.5588 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1066/3620', 'Training loss: 1.5517', '6.4916 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1067/3620', 'Training loss: 1.5515', '7.3391 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1068/3620', 'Training loss: 1.5510', '6.5082 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1069/3620', 'Training loss: 1.5506', '6.5852 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1070/3620', 'Training loss: 1.5502', '6.3613 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1071/3620', 'Training loss: 1.5501', '6.7772 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1072/3620', 'Training loss: 1.5500', '7.1293 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1073/3620', 'Training loss: 1.5498', '7.1618 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1074/3620', 'Training loss: 1.5495', '7.0029 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1075/3620', 'Training loss: 1.5495', '7.2445 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1076/3620', 'Training loss: 1.5495', '6.7504 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1077/3620', 'Training loss: 1.5496', '7.1325 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1078/3620', 'Training loss: 1.5495', '7.4826 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1079/3620', 'Training loss: 1.5492', '7.1156 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1080/3620', 'Training loss: 1.5490', '7.1557 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1081/3620', 'Training loss: 1.5486', '6.7560 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1082/3620', 'Training loss: 1.5483', '7.0728 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1083/3620', 'Training loss: 1.5482', '7.0260 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1084/3620', 'Training loss: 1.5480', '7.9710 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1085/3620', 'Training loss: 1.5479', '6.5871 sec/batch')\n",
      "('Epoch 6/20 ', 'Iteration 1086/3620', 'Training loss: 1.5477', '6.7726 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1087/3620', 'Training loss: 1.6370', '7.3874 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1088/3620', 'Training loss: 1.5729', '6.5102 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1089/3620', 'Training loss: 1.5508', '6.7406 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1090/3620', 'Training loss: 1.5445', '7.2036 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1091/3620', 'Training loss: 1.5399', '6.8791 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1092/3620', 'Training loss: 1.5360', '6.9519 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1093/3620', 'Training loss: 1.5290', '7.0379 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1094/3620', 'Training loss: 1.5254', '7.4329 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1095/3620', 'Training loss: 1.5222', '6.9887 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1096/3620', 'Training loss: 1.5165', '6.8599 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1097/3620', 'Training loss: 1.5185', '6.8561 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1098/3620', 'Training loss: 1.5163', '6.7436 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1099/3620', 'Training loss: 1.5156', '6.9294 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1100/3620', 'Training loss: 1.5145', '6.7209 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1101/3620', 'Training loss: 1.5168', '6.9343 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1102/3620', 'Training loss: 1.5133', '6.9589 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1103/3620', 'Training loss: 1.5114', '6.9586 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1104/3620', 'Training loss: 1.5112', '6.9227 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1105/3620', 'Training loss: 1.5114', '7.0124 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1106/3620', 'Training loss: 1.5133', '6.7218 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1107/3620', 'Training loss: 1.5129', '7.1788 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1108/3620', 'Training loss: 1.5122', '6.9813 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1109/3620', 'Training loss: 1.5114', '6.8982 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1110/3620', 'Training loss: 1.5112', '6.8706 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1111/3620', 'Training loss: 1.5100', '6.7783 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1112/3620', 'Training loss: 1.5095', '6.8198 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1113/3620', 'Training loss: 1.5094', '6.8419 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1114/3620', 'Training loss: 1.5071', '6.6996 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1115/3620', 'Training loss: 1.5066', '6.8528 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1116/3620', 'Training loss: 1.5060', '6.8810 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1117/3620', 'Training loss: 1.5057', '6.8028 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1118/3620', 'Training loss: 1.5057', '6.7755 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1119/3620', 'Training loss: 1.5054', '7.6324 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1120/3620', 'Training loss: 1.5047', '6.7945 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1121/3620', 'Training loss: 1.5046', '6.7528 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1122/3620', 'Training loss: 1.5056', '6.7476 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1123/3620', 'Training loss: 1.5051', '6.6511 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1124/3620', 'Training loss: 1.5038', '6.8896 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1125/3620', 'Training loss: 1.5031', '6.7626 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1126/3620', 'Training loss: 1.5018', '6.6115 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1127/3620', 'Training loss: 1.5006', '9.4583 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1128/3620', 'Training loss: 1.5003', '6.9746 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1129/3620', 'Training loss: 1.4993', '6.8006 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1130/3620', 'Training loss: 1.4984', '8.8201 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1131/3620', 'Training loss: 1.4985', '7.8173 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1132/3620', 'Training loss: 1.4980', '10.7227 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1133/3620', 'Training loss: 1.4971', '7.0660 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1134/3620', 'Training loss: 1.4963', '6.3699 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1135/3620', 'Training loss: 1.4962', '6.1840 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1136/3620', 'Training loss: 1.4960', '7.8007 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1137/3620', 'Training loss: 1.4958', '6.8595 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1138/3620', 'Training loss: 1.4952', '6.2161 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1139/3620', 'Training loss: 1.4954', '6.3295 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1140/3620', 'Training loss: 1.4951', '6.5732 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1141/3620', 'Training loss: 1.4949', '6.8854 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1142/3620', 'Training loss: 1.4952', '6.2713 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1143/3620', 'Training loss: 1.4949', '6.2848 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1144/3620', 'Training loss: 1.4946', '7.1660 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1145/3620', 'Training loss: 1.4944', '6.8184 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1146/3620', 'Training loss: 1.4941', '6.6836 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1147/3620', 'Training loss: 1.4943', '7.8947 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1148/3620', 'Training loss: 1.4938', '11.8278 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1149/3620', 'Training loss: 1.4939', '8.6849 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1150/3620', 'Training loss: 1.4938', '9.7604 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1151/3620', 'Training loss: 1.4944', '7.5925 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1152/3620', 'Training loss: 1.4952', '7.8828 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1153/3620', 'Training loss: 1.4947', '7.1901 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1154/3620', 'Training loss: 1.4950', '9.0958 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1155/3620', 'Training loss: 1.4943', '7.8324 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1156/3620', 'Training loss: 1.4943', '8.6877 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1157/3620', 'Training loss: 1.4942', '8.4815 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1158/3620', 'Training loss: 1.4941', '8.3665 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1159/3620', 'Training loss: 1.4940', '7.5569 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1160/3620', 'Training loss: 1.4944', '7.2270 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1161/3620', 'Training loss: 1.4945', '7.9710 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1162/3620', 'Training loss: 1.4943', '7.3894 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1163/3620', 'Training loss: 1.4944', '6.3908 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1164/3620', 'Training loss: 1.4940', '9.6539 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1165/3620', 'Training loss: 1.4935', '10.0335 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1166/3620', 'Training loss: 1.4935', '8.0854 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1167/3620', 'Training loss: 1.4933', '6.9043 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1168/3620', 'Training loss: 1.4931', '6.8049 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1169/3620', 'Training loss: 1.4929', '7.6276 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1170/3620', 'Training loss: 1.4926', '7.0430 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1171/3620', 'Training loss: 1.4921', '6.7195 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1172/3620', 'Training loss: 1.4915', '7.0252 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1173/3620', 'Training loss: 1.4910', '6.4618 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1174/3620', 'Training loss: 1.4909', '9.9538 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1175/3620', 'Training loss: 1.4908', '10.8228 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1176/3620', 'Training loss: 1.4906', '7.1452 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1177/3620', 'Training loss: 1.4901', '11.4235 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1178/3620', 'Training loss: 1.4894', '8.9516 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1179/3620', 'Training loss: 1.4893', '7.0945 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1180/3620', 'Training loss: 1.4891', '7.0263 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1181/3620', 'Training loss: 1.4889', '7.4237 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1182/3620', 'Training loss: 1.4887', '6.5635 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1183/3620', 'Training loss: 1.4886', '6.6568 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1184/3620', 'Training loss: 1.4885', '6.0986 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1185/3620', 'Training loss: 1.4882', '6.2654 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1186/3620', 'Training loss: 1.4881', '6.6240 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1187/3620', 'Training loss: 1.4876', '6.3311 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1188/3620', 'Training loss: 1.4870', '7.0506 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1189/3620', 'Training loss: 1.4865', '6.0269 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1190/3620', 'Training loss: 1.4860', '6.0775 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1191/3620', 'Training loss: 1.4859', '6.0717 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1192/3620', 'Training loss: 1.4855', '6.0707 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1193/3620', 'Training loss: 1.4851', '6.0823 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1194/3620', 'Training loss: 1.4850', '6.0636 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1195/3620', 'Training loss: 1.4847', '6.1430 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1196/3620', 'Training loss: 1.4843', '6.0915 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1197/3620', 'Training loss: 1.4839', '6.0978 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1198/3620', 'Training loss: 1.4840', '6.1815 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1199/3620', 'Training loss: 1.4838', '6.1157 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1200/3620', 'Training loss: 1.4836', '6.1796 sec/batch')\n",
      "('Validation loss:', 1.3511397, 'Saving checkpoint!')\n",
      "('Epoch 7/20 ', 'Iteration 1201/3620', 'Training loss: 1.4846', '6.1634 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1202/3620', 'Training loss: 1.4842', '6.2298 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1203/3620', 'Training loss: 1.4840', '6.1650 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1204/3620', 'Training loss: 1.4836', '6.3145 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1205/3620', 'Training loss: 1.4834', '6.1115 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1206/3620', 'Training loss: 1.4829', '6.0625 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1207/3620', 'Training loss: 1.4826', '6.1346 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1208/3620', 'Training loss: 1.4825', '6.1560 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1209/3620', 'Training loss: 1.4822', '6.1172 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1210/3620', 'Training loss: 1.4823', '6.1445 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1211/3620', 'Training loss: 1.4819', '6.0903 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1212/3620', 'Training loss: 1.4814', '6.7635 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1213/3620', 'Training loss: 1.4808', '6.1009 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1214/3620', 'Training loss: 1.4806', '6.0811 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1215/3620', 'Training loss: 1.4804', '6.1366 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1216/3620', 'Training loss: 1.4802', '6.1625 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1217/3620', 'Training loss: 1.4799', '6.0983 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1218/3620', 'Training loss: 1.4796', '6.1046 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1219/3620', 'Training loss: 1.4794', '6.0625 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1220/3620', 'Training loss: 1.4789', '6.0437 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1221/3620', 'Training loss: 1.4786', '6.1083 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1222/3620', 'Training loss: 1.4785', '6.0898 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1223/3620', 'Training loss: 1.4782', '6.0385 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1224/3620', 'Training loss: 1.4781', '6.0688 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1225/3620', 'Training loss: 1.4780', '6.0325 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1226/3620', 'Training loss: 1.4778', '6.0526 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1227/3620', 'Training loss: 1.4777', '6.0732 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1228/3620', 'Training loss: 1.4776', '6.1727 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1229/3620', 'Training loss: 1.4776', '6.1070 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1230/3620', 'Training loss: 1.4776', '6.0982 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1231/3620', 'Training loss: 1.4776', '6.1262 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1232/3620', 'Training loss: 1.4774', '6.1676 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1233/3620', 'Training loss: 1.4774', '6.0860 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1234/3620', 'Training loss: 1.4772', '6.0338 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1235/3620', 'Training loss: 1.4773', '6.0568 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1236/3620', 'Training loss: 1.4771', '6.0887 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1237/3620', 'Training loss: 1.4772', '6.1160 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1238/3620', 'Training loss: 1.4772', '6.1025 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1239/3620', 'Training loss: 1.4772', '6.2877 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1240/3620', 'Training loss: 1.4772', '6.1377 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1241/3620', 'Training loss: 1.4768', '6.1598 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1242/3620', 'Training loss: 1.4767', '6.1284 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1243/3620', 'Training loss: 1.4764', '6.1227 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1244/3620', 'Training loss: 1.4764', '6.1132 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1245/3620', 'Training loss: 1.4762', '6.0999 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1246/3620', 'Training loss: 1.4761', '6.1031 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1247/3620', 'Training loss: 1.4760', '6.1348 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1248/3620', 'Training loss: 1.4758', '6.0826 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1249/3620', 'Training loss: 1.4755', '6.1267 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1250/3620', 'Training loss: 1.4752', '6.1635 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1251/3620', 'Training loss: 1.4750', '6.0599 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1252/3620', 'Training loss: 1.4749', '6.1148 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1253/3620', 'Training loss: 1.4749', '6.4110 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1254/3620', 'Training loss: 1.4747', '6.1631 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1255/3620', 'Training loss: 1.4744', '6.0567 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1256/3620', 'Training loss: 1.4745', '6.0806 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1257/3620', 'Training loss: 1.4745', '6.1048 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1258/3620', 'Training loss: 1.4746', '6.1365 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1259/3620', 'Training loss: 1.4745', '6.1000 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1260/3620', 'Training loss: 1.4743', '6.0846 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1261/3620', 'Training loss: 1.4742', '6.7203 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1262/3620', 'Training loss: 1.4738', '6.1421 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1263/3620', 'Training loss: 1.4735', '6.1665 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1264/3620', 'Training loss: 1.4735', '6.0422 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1265/3620', 'Training loss: 1.4734', '6.0620 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1266/3620', 'Training loss: 1.4733', '6.0923 sec/batch')\n",
      "('Epoch 7/20 ', 'Iteration 1267/3620', 'Training loss: 1.4732', '6.0135 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1268/3620', 'Training loss: 1.5978', '6.1168 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1269/3620', 'Training loss: 1.5231', '6.2189 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1270/3620', 'Training loss: 1.4951', '6.1189 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1271/3620', 'Training loss: 1.4880', '6.1231 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1272/3620', 'Training loss: 1.4841', '6.0901 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1273/3620', 'Training loss: 1.4800', '5.9947 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1274/3620', 'Training loss: 1.4728', '6.1364 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1275/3620', 'Training loss: 1.4698', '6.1240 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1276/3620', 'Training loss: 1.4666', '6.1276 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1277/3620', 'Training loss: 1.4616', '6.1109 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1278/3620', 'Training loss: 1.4626', '6.1278 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1279/3620', 'Training loss: 1.4593', '6.1492 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1280/3620', 'Training loss: 1.4583', '6.5808 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1281/3620', 'Training loss: 1.4566', '6.1201 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1282/3620', 'Training loss: 1.4576', '954.1032 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1283/3620', 'Training loss: 1.4539', '10.3021 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1284/3620', 'Training loss: 1.4519', '7.3782 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1285/3620', 'Training loss: 1.4520', '7.6976 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1286/3620', 'Training loss: 1.4521', '7.4535 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1287/3620', 'Training loss: 1.4534', '8.3383 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1288/3620', 'Training loss: 1.4527', '8.4630 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1289/3620', 'Training loss: 1.4515', '8.0577 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1290/3620', 'Training loss: 1.4506', '8.6022 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1291/3620', 'Training loss: 1.4506', '8.3048 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1292/3620', 'Training loss: 1.4493', '6.5135 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1293/3620', 'Training loss: 1.4489', '6.3110 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1294/3620', 'Training loss: 1.4488', '6.2757 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1295/3620', 'Training loss: 1.4464', '7.6326 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1296/3620', 'Training loss: 1.4461', '11.0312 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1297/3620', 'Training loss: 1.4456', '9.0679 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1298/3620', 'Training loss: 1.4453', '6.8322 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1299/3620', 'Training loss: 1.4450', '6.3681 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1300/3620', 'Training loss: 1.4449', '8.6603 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1301/3620', 'Training loss: 1.4444', '9.3908 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1302/3620', 'Training loss: 1.4444', '6.6604 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1303/3620', 'Training loss: 1.4449', '7.2320 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1304/3620', 'Training loss: 1.4448', '6.7747 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1305/3620', 'Training loss: 1.4434', '6.3288 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1306/3620', 'Training loss: 1.4423', '6.2905 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1307/3620', 'Training loss: 1.4409', '6.1875 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1308/3620', 'Training loss: 1.4400', '6.3492 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1309/3620', 'Training loss: 1.4394', '6.1165 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1310/3620', 'Training loss: 1.4387', '6.5786 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1311/3620', 'Training loss: 1.4381', '6.4831 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1312/3620', 'Training loss: 1.4382', '6.1781 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1313/3620', 'Training loss: 1.4376', '6.3257 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1314/3620', 'Training loss: 1.4366', '8.3416 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1315/3620', 'Training loss: 1.4358', '6.4573 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1316/3620', 'Training loss: 1.4356', '6.6582 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1317/3620', 'Training loss: 1.4355', '7.1613 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1318/3620', 'Training loss: 1.4351', '6.8289 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1319/3620', 'Training loss: 1.4344', '6.5683 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1320/3620', 'Training loss: 1.4346', '6.0146 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1321/3620', 'Training loss: 1.4344', '6.1086 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1322/3620', 'Training loss: 1.4342', '6.6082 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1323/3620', 'Training loss: 1.4345', '6.6658 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1324/3620', 'Training loss: 1.4346', '6.0475 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1325/3620', 'Training loss: 1.4345', '6.1891 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1326/3620', 'Training loss: 1.4345', '6.6532 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1327/3620', 'Training loss: 1.4342', '6.6086 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1328/3620', 'Training loss: 1.4344', '6.4112 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1329/3620', 'Training loss: 1.4341', '6.3424 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1330/3620', 'Training loss: 1.4341', '6.1218 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1331/3620', 'Training loss: 1.4341', '6.1346 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1332/3620', 'Training loss: 1.4347', '6.1488 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1333/3620', 'Training loss: 1.4353', '6.2112 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1334/3620', 'Training loss: 1.4346', '6.6232 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1335/3620', 'Training loss: 1.4348', '6.6612 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1336/3620', 'Training loss: 1.4342', '6.2694 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1337/3620', 'Training loss: 1.4341', '6.4939 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1338/3620', 'Training loss: 1.4341', '6.1373 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1339/3620', 'Training loss: 1.4340', '6.6379 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1340/3620', 'Training loss: 1.4341', '6.5539 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1341/3620', 'Training loss: 1.4344', '6.3922 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1342/3620', 'Training loss: 1.4346', '6.6452 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1343/3620', 'Training loss: 1.4344', '6.4448 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1344/3620', 'Training loss: 1.4346', '6.4800 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1345/3620', 'Training loss: 1.4343', '6.5932 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1346/3620', 'Training loss: 1.4337', '6.2459 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1347/3620', 'Training loss: 1.4337', '6.6291 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1348/3620', 'Training loss: 1.4336', '6.5265 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1349/3620', 'Training loss: 1.4332', '6.1813 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1350/3620', 'Training loss: 1.4330', '6.6316 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1351/3620', 'Training loss: 1.4325', '6.5341 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1352/3620', 'Training loss: 1.4321', '6.6400 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1353/3620', 'Training loss: 1.4315', '6.3534 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1354/3620', 'Training loss: 1.4310', '6.4701 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1355/3620', 'Training loss: 1.4309', '6.3950 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1356/3620', 'Training loss: 1.4308', '6.3988 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1357/3620', 'Training loss: 1.4306', '6.4527 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1358/3620', 'Training loss: 1.4302', '6.5543 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1359/3620', 'Training loss: 1.4296', '6.3715 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1360/3620', 'Training loss: 1.4295', '6.4798 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1361/3620', 'Training loss: 1.4293', '6.6174 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1362/3620', 'Training loss: 1.4291', '6.3992 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1363/3620', 'Training loss: 1.4289', '6.4154 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1364/3620', 'Training loss: 1.4286', '6.5526 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1365/3620', 'Training loss: 1.4285', '6.1187 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1366/3620', 'Training loss: 1.4281', '6.2465 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1367/3620', 'Training loss: 1.4281', '6.1049 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1368/3620', 'Training loss: 1.4274', '6.1786 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1369/3620', 'Training loss: 1.4269', '6.0960 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1370/3620', 'Training loss: 1.4263', '6.1042 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1371/3620', 'Training loss: 1.4259', '6.1435 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1372/3620', 'Training loss: 1.4259', '6.2713 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1373/3620', 'Training loss: 1.4254', '6.2508 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1374/3620', 'Training loss: 1.4250', '6.9180 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1375/3620', 'Training loss: 1.4250', '6.2495 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1376/3620', 'Training loss: 1.4247', '6.1718 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1377/3620', 'Training loss: 1.4244', '6.1377 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1378/3620', 'Training loss: 1.4242', '7.5154 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1379/3620', 'Training loss: 1.4243', '6.2818 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1380/3620', 'Training loss: 1.4242', '6.1748 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1381/3620', 'Training loss: 1.4240', '6.1571 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1382/3620', 'Training loss: 1.4238', '6.0913 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1383/3620', 'Training loss: 1.4234', '6.0782 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1384/3620', 'Training loss: 1.4232', '6.1101 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1385/3620', 'Training loss: 1.4229', '6.1601 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1386/3620', 'Training loss: 1.4227', '6.1248 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1387/3620', 'Training loss: 1.4224', '6.0745 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1388/3620', 'Training loss: 1.4222', '6.1684 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1389/3620', 'Training loss: 1.4220', '6.1072 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1390/3620', 'Training loss: 1.4218', '6.6391 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1391/3620', 'Training loss: 1.4219', '6.1110 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1392/3620', 'Training loss: 1.4215', '6.1784 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1393/3620', 'Training loss: 1.4212', '6.0819 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1394/3620', 'Training loss: 1.4207', '6.1127 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1395/3620', 'Training loss: 1.4205', '6.1058 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1396/3620', 'Training loss: 1.4204', '6.1667 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1397/3620', 'Training loss: 1.4203', '6.1203 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1398/3620', 'Training loss: 1.4200', '6.0950 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1399/3620', 'Training loss: 1.4199', '6.1575 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1400/3620', 'Training loss: 1.4197', '6.2467 sec/batch')\n",
      "('Validation loss:', 1.2987095, 'Saving checkpoint!')\n",
      "('Epoch 8/20 ', 'Iteration 1401/3620', 'Training loss: 1.4203', '7.2796 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1402/3620', 'Training loss: 1.4200', '5.9356 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1403/3620', 'Training loss: 1.4201', '6.1842 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1404/3620', 'Training loss: 1.4199', '6.2042 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1405/3620', 'Training loss: 1.4199', '6.1105 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1406/3620', 'Training loss: 1.4199', '6.1751 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1407/3620', 'Training loss: 1.4197', '6.1783 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1408/3620', 'Training loss: 1.4196', '6.2022 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1409/3620', 'Training loss: 1.4196', '6.1203 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1410/3620', 'Training loss: 1.4196', '6.1167 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1411/3620', 'Training loss: 1.4196', '6.1201 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1412/3620', 'Training loss: 1.4196', '6.1597 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1413/3620', 'Training loss: 1.4195', '6.2211 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1414/3620', 'Training loss: 1.4194', '6.2722 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1415/3620', 'Training loss: 1.4195', '6.1310 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1416/3620', 'Training loss: 1.4195', '6.3553 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1417/3620', 'Training loss: 1.4193', '6.5445 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1418/3620', 'Training loss: 1.4194', '6.6654 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1419/3620', 'Training loss: 1.4194', '6.5601 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1420/3620', 'Training loss: 1.4195', '6.2236 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1421/3620', 'Training loss: 1.4196', '6.6355 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1422/3620', 'Training loss: 1.4191', '6.7523 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1423/3620', 'Training loss: 1.4190', '6.3957 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1424/3620', 'Training loss: 1.4188', '6.7607 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1425/3620', 'Training loss: 1.4188', '6.4928 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1426/3620', 'Training loss: 1.4186', '6.5816 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1427/3620', 'Training loss: 1.4186', '6.1393 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1428/3620', 'Training loss: 1.4186', '6.8946 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1429/3620', 'Training loss: 1.4185', '6.4160 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1430/3620', 'Training loss: 1.4182', '6.1447 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1431/3620', 'Training loss: 1.4180', '6.3265 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1432/3620', 'Training loss: 1.4178', '6.4978 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1433/3620', 'Training loss: 1.4178', '6.3120 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1434/3620', 'Training loss: 1.4178', '6.3431 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1435/3620', 'Training loss: 1.4176', '7.5824 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1436/3620', 'Training loss: 1.4174', '5.9651 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1437/3620', 'Training loss: 1.4176', '6.2317 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1438/3620', 'Training loss: 1.4176', '6.3354 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1439/3620', 'Training loss: 1.4178', '6.2911 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1440/3620', 'Training loss: 1.4177', '6.0787 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1441/3620', 'Training loss: 1.4175', '6.3642 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1442/3620', 'Training loss: 1.4175', '6.1986 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1443/3620', 'Training loss: 1.4172', '6.4987 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1444/3620', 'Training loss: 1.4170', '6.5087 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1445/3620', 'Training loss: 1.4170', '6.7205 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1446/3620', 'Training loss: 1.4169', '6.2551 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1447/3620', 'Training loss: 1.4169', '6.3851 sec/batch')\n",
      "('Epoch 8/20 ', 'Iteration 1448/3620', 'Training loss: 1.4167', '6.3735 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1449/3620', 'Training loss: 1.5366', '6.3763 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1450/3620', 'Training loss: 1.4748', '6.4696 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1451/3620', 'Training loss: 1.4494', '6.4426 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1452/3620', 'Training loss: 1.4406', '6.4435 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1453/3620', 'Training loss: 1.4369', '6.5141 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1454/3620', 'Training loss: 1.4320', '6.0135 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1455/3620', 'Training loss: 1.4246', '6.2663 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1456/3620', 'Training loss: 1.4221', '6.2144 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1457/3620', 'Training loss: 1.4194', '6.4426 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1458/3620', 'Training loss: 1.4140', '6.3581 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1459/3620', 'Training loss: 1.4151', '6.1442 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1460/3620', 'Training loss: 1.4117', '6.2658 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1461/3620', 'Training loss: 1.4111', '6.5452 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1462/3620', 'Training loss: 1.4094', '6.3510 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1463/3620', 'Training loss: 1.4108', '6.3179 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1464/3620', 'Training loss: 1.4068', '6.2643 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1465/3620', 'Training loss: 1.4041', '6.4028 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1466/3620', 'Training loss: 1.4045', '6.1127 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1467/3620', 'Training loss: 1.4045', '6.1743 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1468/3620', 'Training loss: 1.4060', '6.0911 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1469/3620', 'Training loss: 1.4052', '6.1230 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1470/3620', 'Training loss: 1.4039', '6.1502 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1471/3620', 'Training loss: 1.4030', '6.0862 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1472/3620', 'Training loss: 1.4029', '6.1192 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1473/3620', 'Training loss: 1.4021', '6.3223 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1474/3620', 'Training loss: 1.4018', '6.5157 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1475/3620', 'Training loss: 1.4014', '6.2299 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1476/3620', 'Training loss: 1.3990', '6.8109 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1477/3620', 'Training loss: 1.3986', '6.2855 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1478/3620', 'Training loss: 1.3980', '6.2179 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1479/3620', 'Training loss: 1.3978', '6.1396 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1480/3620', 'Training loss: 1.3979', '7.5457 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1481/3620', 'Training loss: 1.3978', '6.4675 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1482/3620', 'Training loss: 1.3970', '7.4076 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1483/3620', 'Training loss: 1.3970', '6.1967 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1484/3620', 'Training loss: 1.3977', '6.6818 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1485/3620', 'Training loss: 1.3974', '6.3707 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1486/3620', 'Training loss: 1.3961', '6.0989 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1487/3620', 'Training loss: 1.3949', '6.1682 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1488/3620', 'Training loss: 1.3934', '6.1563 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1489/3620', 'Training loss: 1.3923', '6.1217 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1490/3620', 'Training loss: 1.3917', '6.4480 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1491/3620', 'Training loss: 1.3908', '6.0667 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1492/3620', 'Training loss: 1.3903', '6.1882 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1493/3620', 'Training loss: 1.3907', '6.2779 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1494/3620', 'Training loss: 1.3902', '7.0270 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1495/3620', 'Training loss: 1.3894', '5.9794 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1496/3620', 'Training loss: 1.3889', '6.0757 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1497/3620', 'Training loss: 1.3888', '6.1924 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1498/3620', 'Training loss: 1.3885', '6.2198 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1499/3620', 'Training loss: 1.3881', '6.0891 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1500/3620', 'Training loss: 1.3874', '6.1285 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1501/3620', 'Training loss: 1.3877', '6.5530 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1502/3620', 'Training loss: 1.3875', '6.1962 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1503/3620', 'Training loss: 1.3874', '6.1575 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1504/3620', 'Training loss: 1.3879', '6.0750 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1505/3620', 'Training loss: 1.3875', '6.1126 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1506/3620', 'Training loss: 1.3876', '6.1339 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1507/3620', 'Training loss: 1.3875', '7.3566 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1508/3620', 'Training loss: 1.3872', '6.8312 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1509/3620', 'Training loss: 1.3873', '6.6132 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1510/3620', 'Training loss: 1.3869', '6.0966 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1511/3620', 'Training loss: 1.3869', '6.2183 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1512/3620', 'Training loss: 1.3869', '6.1861 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1513/3620', 'Training loss: 1.3875', '6.1165 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1514/3620', 'Training loss: 1.3881', '6.0964 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1515/3620', 'Training loss: 1.3875', '6.2301 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1516/3620', 'Training loss: 1.3876', '6.5444 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1517/3620', 'Training loss: 1.3871', '6.8024 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1518/3620', 'Training loss: 1.3870', '6.9131 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1519/3620', 'Training loss: 1.3869', '7.0384 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1520/3620', 'Training loss: 1.3868', '7.0548 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1521/3620', 'Training loss: 1.3869', '6.7686 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1522/3620', 'Training loss: 1.3872', '7.7906 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1523/3620', 'Training loss: 1.3873', '6.5513 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1524/3620', 'Training loss: 1.3871', '6.3386 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1525/3620', 'Training loss: 1.3872', '6.6420 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1526/3620', 'Training loss: 1.3869', '6.1940 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1527/3620', 'Training loss: 1.3865', '7.0336 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1528/3620', 'Training loss: 1.3865', '6.9154 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1529/3620', 'Training loss: 1.3863', '7.7541 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1530/3620', 'Training loss: 1.3860', '6.2522 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1531/3620', 'Training loss: 1.3859', '6.2498 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1532/3620', 'Training loss: 1.3856', '6.8923 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1533/3620', 'Training loss: 1.3852', '6.3998 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1534/3620', 'Training loss: 1.3847', '6.2594 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1535/3620', 'Training loss: 1.3841', '6.4789 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1536/3620', 'Training loss: 1.3841', '6.1688 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1537/3620', 'Training loss: 1.3840', '6.1717 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1538/3620', 'Training loss: 1.3839', '6.5145 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1539/3620', 'Training loss: 1.3835', '6.4043 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1540/3620', 'Training loss: 1.3830', '6.5627 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1541/3620', 'Training loss: 1.3830', '6.2186 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1542/3620', 'Training loss: 1.3827', '6.3204 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1543/3620', 'Training loss: 1.3825', '6.3979 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1544/3620', 'Training loss: 1.3823', '6.5388 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1545/3620', 'Training loss: 1.3821', '6.1273 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1546/3620', 'Training loss: 1.3819', '6.1420 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1547/3620', 'Training loss: 1.3816', '6.1890 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1548/3620', 'Training loss: 1.3815', '6.2154 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1549/3620', 'Training loss: 1.3811', '6.3677 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1550/3620', 'Training loss: 1.3806', '6.1456 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1551/3620', 'Training loss: 1.3802', '6.8274 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1552/3620', 'Training loss: 1.3798', '7.3613 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1553/3620', 'Training loss: 1.3798', '6.4362 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1554/3620', 'Training loss: 1.3794', '6.8896 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1555/3620', 'Training loss: 1.3790', '6.8834 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1556/3620', 'Training loss: 1.3792', '6.7434 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1557/3620', 'Training loss: 1.3789', '6.4426 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1558/3620', 'Training loss: 1.3786', '6.5360 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1559/3620', 'Training loss: 1.3782', '6.3761 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1560/3620', 'Training loss: 1.3784', '6.4189 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1561/3620', 'Training loss: 1.3783', '7.1723 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1562/3620', 'Training loss: 1.3781', '6.3443 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1563/3620', 'Training loss: 1.3780', '6.7581 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1564/3620', 'Training loss: 1.3777', '6.2548 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1565/3620', 'Training loss: 1.3776', '6.3659 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1566/3620', 'Training loss: 1.3772', '6.7286 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1567/3620', 'Training loss: 1.3771', '6.1610 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1568/3620', 'Training loss: 1.3768', '7.3809 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1569/3620', 'Training loss: 1.3765', '6.4590 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1570/3620', 'Training loss: 1.3765', '6.2410 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1571/3620', 'Training loss: 1.3763', '7.0130 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1572/3620', 'Training loss: 1.3765', '7.1421 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1573/3620', 'Training loss: 1.3761', '6.8703 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1574/3620', 'Training loss: 1.3757', '7.8529 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1575/3620', 'Training loss: 1.3752', '6.3000 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1576/3620', 'Training loss: 1.3751', '6.4394 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1577/3620', 'Training loss: 1.3749', '6.0857 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1578/3620', 'Training loss: 1.3748', '6.1064 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1579/3620', 'Training loss: 1.3745', '6.0817 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1580/3620', 'Training loss: 1.3743', '6.0983 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1581/3620', 'Training loss: 1.3742', '6.0394 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1582/3620', 'Training loss: 1.3737', '6.0718 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1583/3620', 'Training loss: 1.3734', '6.0426 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1584/3620', 'Training loss: 1.3734', '6.0427 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1585/3620', 'Training loss: 1.3732', '6.0989 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1586/3620', 'Training loss: 1.3732', '6.1539 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1587/3620', 'Training loss: 1.3733', '6.0867 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1588/3620', 'Training loss: 1.3731', '6.0413 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1589/3620', 'Training loss: 1.3730', '6.1630 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1590/3620', 'Training loss: 1.3729', '6.1588 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1591/3620', 'Training loss: 1.3729', '6.0288 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1592/3620', 'Training loss: 1.3730', '6.0808 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1593/3620', 'Training loss: 1.3730', '6.0999 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1594/3620', 'Training loss: 1.3730', '6.1369 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1595/3620', 'Training loss: 1.3729', '6.1153 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1596/3620', 'Training loss: 1.3729', '6.0548 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1597/3620', 'Training loss: 1.3731', '6.0775 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1598/3620', 'Training loss: 1.3728', '6.0783 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1599/3620', 'Training loss: 1.3729', '6.0174 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1600/3620', 'Training loss: 1.3729', '6.0592 sec/batch')\n",
      "('Validation loss:', 1.2557144, 'Saving checkpoint!')\n",
      "('Epoch 9/20 ', 'Iteration 1601/3620', 'Training loss: 1.3739', '6.8820 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1602/3620', 'Training loss: 1.3739', '5.9391 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1603/3620', 'Training loss: 1.3737', '6.0754 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1604/3620', 'Training loss: 1.3735', '6.0667 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1605/3620', 'Training loss: 1.3734', '6.0918 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1606/3620', 'Training loss: 1.3735', '6.0962 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1607/3620', 'Training loss: 1.3734', '6.5716 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1608/3620', 'Training loss: 1.3734', '6.1341 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1609/3620', 'Training loss: 1.3735', '6.1399 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1610/3620', 'Training loss: 1.3734', '6.0827 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1611/3620', 'Training loss: 1.3731', '6.0876 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1612/3620', 'Training loss: 1.3728', '6.0556 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1613/3620', 'Training loss: 1.3727', '6.0237 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1614/3620', 'Training loss: 1.3727', '6.1364 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1615/3620', 'Training loss: 1.3727', '6.0847 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1616/3620', 'Training loss: 1.3726', '6.0558 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1617/3620', 'Training loss: 1.3725', '6.3163 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1618/3620', 'Training loss: 1.3727', '6.0924 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1619/3620', 'Training loss: 1.3728', '6.0593 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1620/3620', 'Training loss: 1.3730', '6.1332 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1621/3620', 'Training loss: 1.3730', '7.0671 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1622/3620', 'Training loss: 1.3729', '7.9042 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1623/3620', 'Training loss: 1.3729', '5.9715 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1624/3620', 'Training loss: 1.3726', '885.3289 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1625/3620', 'Training loss: 1.3724', '8.8625 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1626/3620', 'Training loss: 1.3725', '6.3411 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1627/3620', 'Training loss: 1.3724', '6.2893 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1628/3620', 'Training loss: 1.3724', '6.4466 sec/batch')\n",
      "('Epoch 9/20 ', 'Iteration 1629/3620', 'Training loss: 1.3723', '6.3136 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1630/3620', 'Training loss: 1.4845', '6.3078 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1631/3620', 'Training loss: 1.4282', '6.3815 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1632/3620', 'Training loss: 1.4052', '6.2461 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1633/3620', 'Training loss: 1.3989', '6.0999 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1634/3620', 'Training loss: 1.3939', '6.0662 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1635/3620', 'Training loss: 1.3893', '6.1670 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1636/3620', 'Training loss: 1.3815', '6.0418 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1637/3620', 'Training loss: 1.3801', '6.0911 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1638/3620', 'Training loss: 1.3768', '6.1748 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1639/3620', 'Training loss: 1.3713', '6.0868 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1640/3620', 'Training loss: 1.3722', '6.0922 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1641/3620', 'Training loss: 1.3687', '6.1114 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1642/3620', 'Training loss: 1.3677', '6.0234 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1643/3620', 'Training loss: 1.3657', '6.2508 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1644/3620', 'Training loss: 1.3670', '6.1157 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1645/3620', 'Training loss: 1.3637', '6.1776 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1646/3620', 'Training loss: 1.3615', '6.1321 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1647/3620', 'Training loss: 1.3625', '6.1213 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1648/3620', 'Training loss: 1.3624', '6.2934 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1649/3620', 'Training loss: 1.3634', '6.0563 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1650/3620', 'Training loss: 1.3624', '6.1362 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1651/3620', 'Training loss: 1.3618', '6.0837 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1652/3620', 'Training loss: 1.3611', '6.0362 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1653/3620', 'Training loss: 1.3606', '6.1604 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1654/3620', 'Training loss: 1.3602', '7.0655 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1655/3620', 'Training loss: 1.3601', '6.5789 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1656/3620', 'Training loss: 1.3600', '6.1029 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1657/3620', 'Training loss: 1.3577', '6.1037 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1658/3620', 'Training loss: 1.3572', '6.0703 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1659/3620', 'Training loss: 1.3565', '6.0662 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1660/3620', 'Training loss: 1.3563', '6.0791 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1661/3620', 'Training loss: 1.3564', '6.0861 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1662/3620', 'Training loss: 1.3563', '6.0682 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1663/3620', 'Training loss: 1.3556', '6.0560 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1664/3620', 'Training loss: 1.3551', '6.3777 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1665/3620', 'Training loss: 1.3556', '6.0148 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1666/3620', 'Training loss: 1.3554', '6.1739 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1667/3620', 'Training loss: 1.3543', '6.0475 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1668/3620', 'Training loss: 1.3534', '6.0102 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1669/3620', 'Training loss: 1.3518', '6.0466 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1670/3620', 'Training loss: 1.3507', '6.0487 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1671/3620', 'Training loss: 1.3502', '6.0498 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1672/3620', 'Training loss: 1.3496', '6.0965 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1673/3620', 'Training loss: 1.3489', '6.1806 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1674/3620', 'Training loss: 1.3491', '6.0842 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1675/3620', 'Training loss: 1.3487', '6.0153 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1676/3620', 'Training loss: 1.3477', '6.0548 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1677/3620', 'Training loss: 1.3472', '6.1687 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1678/3620', 'Training loss: 1.3472', '6.0665 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1679/3620', 'Training loss: 1.3472', '6.0319 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1680/3620', 'Training loss: 1.3469', '6.0340 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1681/3620', 'Training loss: 1.3462', '6.0836 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1682/3620', 'Training loss: 1.3463', '6.0902 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1683/3620', 'Training loss: 1.3462', '6.1777 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1684/3620', 'Training loss: 1.3462', '6.4469 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1685/3620', 'Training loss: 1.3466', '6.5773 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1686/3620', 'Training loss: 1.3463', '5.9245 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1687/3620', 'Training loss: 1.3463', '6.0468 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1688/3620', 'Training loss: 1.3464', '6.0476 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1689/3620', 'Training loss: 1.3463', '6.0457 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1690/3620', 'Training loss: 1.3465', '5.9774 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1691/3620', 'Training loss: 1.3463', '6.0890 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1692/3620', 'Training loss: 1.3464', '6.0642 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1693/3620', 'Training loss: 1.3465', '6.0623 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1694/3620', 'Training loss: 1.3472', '6.0388 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1695/3620', 'Training loss: 1.3479', '6.0725 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1696/3620', 'Training loss: 1.3474', '6.0371 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1697/3620', 'Training loss: 1.3475', '6.0594 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1698/3620', 'Training loss: 1.3470', '6.0597 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1699/3620', 'Training loss: 1.3469', '6.0288 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1700/3620', 'Training loss: 1.3467', '6.0949 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1701/3620', 'Training loss: 1.3468', '6.0536 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1702/3620', 'Training loss: 1.3469', '6.0357 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1703/3620', 'Training loss: 1.3474', '6.0523 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1704/3620', 'Training loss: 1.3476', '6.0288 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1705/3620', 'Training loss: 1.3475', '6.0514 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1706/3620', 'Training loss: 1.3476', '6.0478 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1707/3620', 'Training loss: 1.3474', '6.1833 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1708/3620', 'Training loss: 1.3469', '6.3313 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1709/3620', 'Training loss: 1.3469', '6.0993 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1710/3620', 'Training loss: 1.3466', '6.0927 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1711/3620', 'Training loss: 1.3463', '6.0436 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1712/3620', 'Training loss: 1.3461', '6.0487 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1713/3620', 'Training loss: 1.3456', '6.0507 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1714/3620', 'Training loss: 1.3453', '6.0544 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1715/3620', 'Training loss: 1.3447', '6.0284 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1716/3620', 'Training loss: 1.3442', '6.0507 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1717/3620', 'Training loss: 1.3443', '6.0201 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1718/3620', 'Training loss: 1.3443', '6.0434 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1719/3620', 'Training loss: 1.3441', '6.1033 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1720/3620', 'Training loss: 1.3439', '6.0670 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1721/3620', 'Training loss: 1.3432', '6.0525 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1722/3620', 'Training loss: 1.3432', '6.1870 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1723/3620', 'Training loss: 1.3430', '6.0295 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1724/3620', 'Training loss: 1.3429', '6.0661 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1725/3620', 'Training loss: 1.3427', '6.0499 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1726/3620', 'Training loss: 1.3425', '6.0700 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1727/3620', 'Training loss: 1.3425', '6.0315 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1728/3620', 'Training loss: 1.3422', '6.0487 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1729/3620', 'Training loss: 1.3421', '6.0488 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1730/3620', 'Training loss: 1.3416', '6.0226 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1731/3620', 'Training loss: 1.3412', '6.0811 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1732/3620', 'Training loss: 1.3408', '6.0642 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1733/3620', 'Training loss: 1.3405', '6.0609 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1734/3620', 'Training loss: 1.3406', '6.2604 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1735/3620', 'Training loss: 1.3402', '6.0366 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1736/3620', 'Training loss: 1.3400', '6.1757 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1737/3620', 'Training loss: 1.3401', '147.3848 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1738/3620', 'Training loss: 1.3398', '9.0923 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1739/3620', 'Training loss: 1.3396', '8.1088 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1740/3620', 'Training loss: 1.3393', '7.5198 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1741/3620', 'Training loss: 1.3396', '7.5062 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1742/3620', 'Training loss: 1.3396', '7.2180 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1743/3620', 'Training loss: 1.3395', '6.5089 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1744/3620', 'Training loss: 1.3394', '7.2984 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1745/3620', 'Training loss: 1.3391', '6.6974 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1746/3620', 'Training loss: 1.3390', '8.6829 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1747/3620', 'Training loss: 1.3387', '7.4690 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1748/3620', 'Training loss: 1.3385', '7.1212 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1749/3620', 'Training loss: 1.3384', '7.8240 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1750/3620', 'Training loss: 1.3380', '6.5478 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1751/3620', 'Training loss: 1.3379', '7.2197 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1752/3620', 'Training loss: 1.3377', '7.3489 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1753/3620', 'Training loss: 1.3379', '11.9196 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1754/3620', 'Training loss: 1.3375', '6.4721 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1755/3620', 'Training loss: 1.3371', '6.1606 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1756/3620', 'Training loss: 1.3366', '6.3040 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1757/3620', 'Training loss: 1.3366', '6.0878 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1758/3620', 'Training loss: 1.3365', '6.2720 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1759/3620', 'Training loss: 1.3364', '6.2242 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1760/3620', 'Training loss: 1.3362', '6.3007 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1761/3620', 'Training loss: 1.3360', '6.3187 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1762/3620', 'Training loss: 1.3358', '6.6005 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1763/3620', 'Training loss: 1.3354', '6.4843 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1764/3620', 'Training loss: 1.3352', '6.4014 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1765/3620', 'Training loss: 1.3351', '6.3147 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1766/3620', 'Training loss: 1.3349', '6.2988 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1767/3620', 'Training loss: 1.3349', '6.3198 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1768/3620', 'Training loss: 1.3350', '7.4283 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1769/3620', 'Training loss: 1.3348', '7.1946 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1770/3620', 'Training loss: 1.3348', '6.4201 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1771/3620', 'Training loss: 1.3347', '7.3395 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1772/3620', 'Training loss: 1.3347', '8.6978 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1773/3620', 'Training loss: 1.3348', '7.7197 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1774/3620', 'Training loss: 1.3348', '6.4590 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1775/3620', 'Training loss: 1.3347', '6.4681 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1776/3620', 'Training loss: 1.3347', '9.6272 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1777/3620', 'Training loss: 1.3346', '9.3474 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1778/3620', 'Training loss: 1.3348', '6.6697 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1779/3620', 'Training loss: 1.3346', '6.5961 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1780/3620', 'Training loss: 1.3347', '6.5953 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1781/3620', 'Training loss: 1.3347', '7.1804 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1782/3620', 'Training loss: 1.3349', '6.7280 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1783/3620', 'Training loss: 1.3350', '7.0676 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1784/3620', 'Training loss: 1.3346', '7.3509 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1785/3620', 'Training loss: 1.3345', '6.4513 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1786/3620', 'Training loss: 1.3343', '6.9490 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1787/3620', 'Training loss: 1.3343', '6.8436 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1788/3620', 'Training loss: 1.3343', '8.7375 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1789/3620', 'Training loss: 1.3343', '6.1002 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1790/3620', 'Training loss: 1.3343', '6.1176 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1791/3620', 'Training loss: 1.3342', '6.5410 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1792/3620', 'Training loss: 1.3339', '6.2173 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1793/3620', 'Training loss: 1.3337', '7.4161 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1794/3620', 'Training loss: 1.3337', '6.8536 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1795/3620', 'Training loss: 1.3337', '7.8445 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1796/3620', 'Training loss: 1.3338', '8.0025 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1797/3620', 'Training loss: 1.3337', '6.2700 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1798/3620', 'Training loss: 1.3336', '6.0396 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1799/3620', 'Training loss: 1.3338', '6.0945 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1800/3620', 'Training loss: 1.3338', '6.0162 sec/batch')\n",
      "('Validation loss:', 1.2248751, 'Saving checkpoint!')\n",
      "('Epoch 10/20 ', 'Iteration 1801/3620', 'Training loss: 1.3352', '8.8741 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1802/3620', 'Training loss: 1.3352', '10.1822 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1803/3620', 'Training loss: 1.3351', '6.8607 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1804/3620', 'Training loss: 1.3351', '6.3407 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1805/3620', 'Training loss: 1.3349', '6.9183 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1806/3620', 'Training loss: 1.3347', '6.5623 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1807/3620', 'Training loss: 1.3347', '7.0047 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1808/3620', 'Training loss: 1.3347', '10.2174 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1809/3620', 'Training loss: 1.3348', '7.8304 sec/batch')\n",
      "('Epoch 10/20 ', 'Iteration 1810/3620', 'Training loss: 1.3347', '6.8034 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1811/3620', 'Training loss: 1.4385', '6.3483 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1812/3620', 'Training loss: 1.3853', '8.0779 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1813/3620', 'Training loss: 1.3631', '6.4364 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1814/3620', 'Training loss: 1.3575', '7.9982 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1815/3620', 'Training loss: 1.3561', '8.4598 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1816/3620', 'Training loss: 1.3533', '6.8151 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1817/3620', 'Training loss: 1.3466', '6.6759 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1818/3620', 'Training loss: 1.3447', '6.4322 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1819/3620', 'Training loss: 1.3412', '6.9271 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1820/3620', 'Training loss: 1.3362', '7.0150 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1821/3620', 'Training loss: 1.3377', '6.7276 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1822/3620', 'Training loss: 1.3343', '6.4983 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1823/3620', 'Training loss: 1.3341', '7.3433 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1824/3620', 'Training loss: 1.3328', '10.1184 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1825/3620', 'Training loss: 1.3344', '7.6323 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1826/3620', 'Training loss: 1.3314', '11.6640 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1827/3620', 'Training loss: 1.3296', '7.3201 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1828/3620', 'Training loss: 1.3301', '7.3155 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1829/3620', 'Training loss: 1.3302', '7.5489 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1830/3620', 'Training loss: 1.3313', '7.4128 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1831/3620', 'Training loss: 1.3307', '6.6768 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1832/3620', 'Training loss: 1.3292', '7.3628 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1833/3620', 'Training loss: 1.3287', '6.5667 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1834/3620', 'Training loss: 1.3284', '6.9444 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1835/3620', 'Training loss: 1.3278', '6.9378 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1836/3620', 'Training loss: 1.3274', '6.3831 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1837/3620', 'Training loss: 1.3273', '6.6319 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1838/3620', 'Training loss: 1.3248', '6.7234 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1839/3620', 'Training loss: 1.3243', '10.7546 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1840/3620', 'Training loss: 1.3237', '8.6176 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1841/3620', 'Training loss: 1.3234', '8.7348 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1842/3620', 'Training loss: 1.3236', '6.7113 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1843/3620', 'Training loss: 1.3236', '7.0113 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1844/3620', 'Training loss: 1.3229', '6.5146 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1845/3620', 'Training loss: 1.3227', '7.1277 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1846/3620', 'Training loss: 1.3235', '6.4078 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1847/3620', 'Training loss: 1.3233', '7.4078 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1848/3620', 'Training loss: 1.3222', '7.4044 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1849/3620', 'Training loss: 1.3213', '6.7941 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1850/3620', 'Training loss: 1.3200', '7.3833 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1851/3620', 'Training loss: 1.3191', '6.9885 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1852/3620', 'Training loss: 1.3186', '7.2952 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1853/3620', 'Training loss: 1.3176', '6.7170 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1854/3620', 'Training loss: 1.3170', '8.9925 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1855/3620', 'Training loss: 1.3174', '7.2351 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1856/3620', 'Training loss: 1.3171', '7.6805 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1857/3620', 'Training loss: 1.3162', '6.4102 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1858/3620', 'Training loss: 1.3158', '6.5233 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1859/3620', 'Training loss: 1.3157', '6.6957 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1860/3620', 'Training loss: 1.3158', '6.5843 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1861/3620', 'Training loss: 1.3154', '6.6302 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1862/3620', 'Training loss: 1.3147', '7.1830 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1863/3620', 'Training loss: 1.3149', '6.7168 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1864/3620', 'Training loss: 1.3146', '6.5932 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1865/3620', 'Training loss: 1.3144', '6.4518 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1866/3620', 'Training loss: 1.3146', '6.5347 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1867/3620', 'Training loss: 1.3144', '8.1096 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1868/3620', 'Training loss: 1.3143', '6.3868 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1869/3620', 'Training loss: 1.3141', '6.4870 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1870/3620', 'Training loss: 1.3139', '6.7799 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1871/3620', 'Training loss: 1.3143', '6.5139 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1872/3620', 'Training loss: 1.3140', '6.6809 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1873/3620', 'Training loss: 1.3141', '7.1201 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1874/3620', 'Training loss: 1.3143', '7.3249 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1875/3620', 'Training loss: 1.3148', '7.5168 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1876/3620', 'Training loss: 1.3154', '7.1401 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1877/3620', 'Training loss: 1.3148', '6.0821 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1878/3620', 'Training loss: 1.3150', '6.0776 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1879/3620', 'Training loss: 1.3146', '6.0603 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1880/3620', 'Training loss: 1.3146', '6.0258 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1881/3620', 'Training loss: 1.3146', '7.6988 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1882/3620', 'Training loss: 1.3147', '6.2066 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1883/3620', 'Training loss: 1.3149', '6.0565 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1884/3620', 'Training loss: 1.3153', '6.0646 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1885/3620', 'Training loss: 1.3156', '6.0592 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1886/3620', 'Training loss: 1.3155', '6.0479 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1887/3620', 'Training loss: 1.3157', '6.0623 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1888/3620', 'Training loss: 1.3154', '6.0450 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1889/3620', 'Training loss: 1.3151', '6.0481 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1890/3620', 'Training loss: 1.3150', '6.0935 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1891/3620', 'Training loss: 1.3148', '12.3320 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1892/3620', 'Training loss: 1.3145', '8.1384 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1893/3620', 'Training loss: 1.3144', '6.3182 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1894/3620', 'Training loss: 1.3140', '7.6266 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1895/3620', 'Training loss: 1.3137', '6.2831 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1896/3620', 'Training loss: 1.3132', '6.2190 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1897/3620', 'Training loss: 1.3128', '6.1698 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1898/3620', 'Training loss: 1.3128', '6.3227 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1899/3620', 'Training loss: 1.3127', '6.2620 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1900/3620', 'Training loss: 1.3126', '6.1211 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1901/3620', 'Training loss: 1.3122', '6.1814 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1902/3620', 'Training loss: 1.3116', '6.1597 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1903/3620', 'Training loss: 1.3116', '6.1432 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1904/3620', 'Training loss: 1.3114', '6.0873 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1905/3620', 'Training loss: 1.3113', '6.1635 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1906/3620', 'Training loss: 1.3112', '7.8578 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1907/3620', 'Training loss: 1.3111', '7.4685 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1908/3620', 'Training loss: 1.3110', '6.5541 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1909/3620', 'Training loss: 1.3107', '6.3686 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1910/3620', 'Training loss: 1.3107', '8.2702 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1911/3620', 'Training loss: 1.3102', '6.5628 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1912/3620', 'Training loss: 1.3098', '7.2105 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1913/3620', 'Training loss: 1.3094', '6.2958 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1914/3620', 'Training loss: 1.3091', '5.9247 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1915/3620', 'Training loss: 1.3091', '6.1017 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1916/3620', 'Training loss: 1.3088', '7.2955 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1917/3620', 'Training loss: 1.3086', '6.4465 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1918/3620', 'Training loss: 1.3087', '6.3949 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1919/3620', 'Training loss: 1.3084', '6.0588 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1920/3620', 'Training loss: 1.3083', '6.0667 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1921/3620', 'Training loss: 1.3080', '6.0910 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1922/3620', 'Training loss: 1.3082', '6.0728 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1923/3620', 'Training loss: 1.3082', '6.0774 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1924/3620', 'Training loss: 1.3080', '6.3698 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1925/3620', 'Training loss: 1.3080', '6.2542 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1926/3620', 'Training loss: 1.3077', '6.0970 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1927/3620', 'Training loss: 1.3076', '6.7849 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1928/3620', 'Training loss: 1.3073', '6.1875 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1929/3620', 'Training loss: 1.3071', '6.2425 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1930/3620', 'Training loss: 1.3069', '6.1687 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1931/3620', 'Training loss: 1.3067', '6.3725 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1932/3620', 'Training loss: 1.3067', '7.1470 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1933/3620', 'Training loss: 1.3066', '6.0974 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1934/3620', 'Training loss: 1.3068', '6.2691 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1935/3620', 'Training loss: 1.3065', '7.9093 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1936/3620', 'Training loss: 1.3060', '6.0857 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1937/3620', 'Training loss: 1.3056', '6.1687 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1938/3620', 'Training loss: 1.3055', '6.0566 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1939/3620', 'Training loss: 1.3054', '6.1215 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1940/3620', 'Training loss: 1.3053', '6.8887 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1941/3620', 'Training loss: 1.3052', '6.2477 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1942/3620', 'Training loss: 1.3051', '6.5831 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1943/3620', 'Training loss: 1.3049', '6.0790 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1944/3620', 'Training loss: 1.3045', '6.0809 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1945/3620', 'Training loss: 1.3043', '6.0675 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1946/3620', 'Training loss: 1.3042', '6.1099 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1947/3620', 'Training loss: 1.3040', '6.0640 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1948/3620', 'Training loss: 1.3040', '6.1122 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1949/3620', 'Training loss: 1.3041', '6.0626 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1950/3620', 'Training loss: 1.3040', '6.0663 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1951/3620', 'Training loss: 1.3040', '6.0832 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1952/3620', 'Training loss: 1.3039', '6.0920 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1953/3620', 'Training loss: 1.3039', '6.1015 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1954/3620', 'Training loss: 1.3040', '6.1326 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1955/3620', 'Training loss: 1.3040', '6.2504 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1956/3620', 'Training loss: 1.3040', '6.1166 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1957/3620', 'Training loss: 1.3040', '6.0730 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1958/3620', 'Training loss: 1.3040', '6.0940 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1959/3620', 'Training loss: 1.3042', '6.0691 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1960/3620', 'Training loss: 1.3040', '6.0815 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1961/3620', 'Training loss: 1.3041', '6.1780 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1962/3620', 'Training loss: 1.3042', '6.1064 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1963/3620', 'Training loss: 1.3043', '6.1147 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1964/3620', 'Training loss: 1.3044', '6.0433 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1965/3620', 'Training loss: 1.3041', '6.0968 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1966/3620', 'Training loss: 1.3040', '6.1553 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1967/3620', 'Training loss: 1.3038', '7.1857 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1968/3620', 'Training loss: 1.3038', '6.1116 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1969/3620', 'Training loss: 1.3038', '6.0110 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1970/3620', 'Training loss: 1.3038', '6.0932 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1971/3620', 'Training loss: 1.3039', '6.0329 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1972/3620', 'Training loss: 1.3038', '6.0379 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1973/3620', 'Training loss: 1.3035', '6.0273 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1974/3620', 'Training loss: 1.3033', '6.0710 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1975/3620', 'Training loss: 1.3032', '6.2857 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1976/3620', 'Training loss: 1.3033', '6.0890 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1977/3620', 'Training loss: 1.3035', '6.1613 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1978/3620', 'Training loss: 1.3033', '6.0239 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1979/3620', 'Training loss: 1.3032', '6.0430 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1980/3620', 'Training loss: 1.3034', '6.0895 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1981/3620', 'Training loss: 1.3035', '6.0830 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1982/3620', 'Training loss: 1.3037', '7.2900 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1983/3620', 'Training loss: 1.3038', '6.9112 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1984/3620', 'Training loss: 1.3037', '6.6837 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1985/3620', 'Training loss: 1.3038', '7.4164 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1986/3620', 'Training loss: 1.3036', '6.6936 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1987/3620', 'Training loss: 1.3034', '9.1214 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1988/3620', 'Training loss: 1.3035', '6.9248 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1989/3620', 'Training loss: 1.3035', '7.7669 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1990/3620', 'Training loss: 1.3036', '6.8228 sec/batch')\n",
      "('Epoch 11/20 ', 'Iteration 1991/3620', 'Training loss: 1.3035', '6.4456 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 1992/3620', 'Training loss: 1.4225', '7.6834 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 1993/3620', 'Training loss: 1.3577', '7.0411 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 1994/3620', 'Training loss: 1.3395', '6.4317 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 1995/3620', 'Training loss: 1.3378', '6.9714 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 1996/3620', 'Training loss: 1.3340', '6.9839 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 1997/3620', 'Training loss: 1.3260', '6.8471 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 1998/3620', 'Training loss: 1.3201', '7.1125 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 1999/3620', 'Training loss: 1.3200', '6.1684 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2000/3620', 'Training loss: 1.3163', '7.0819 sec/batch')\n",
      "('Validation loss:', 1.2002058, 'Saving checkpoint!')\n",
      "('Epoch 12/20 ', 'Iteration 2001/3620', 'Training loss: 1.3247', '7.6236 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2002/3620', 'Training loss: 1.3247', '6.5048 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2003/3620', 'Training loss: 1.3212', '6.6137 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2004/3620', 'Training loss: 1.3204', '6.6625 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2005/3620', 'Training loss: 1.3186', '6.5851 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2006/3620', 'Training loss: 1.3197', '6.4976 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2007/3620', 'Training loss: 1.3152', '6.7027 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2008/3620', 'Training loss: 1.3122', '6.4354 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2009/3620', 'Training loss: 1.3120', '6.4572 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2010/3620', 'Training loss: 1.3116', '6.2950 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2011/3620', 'Training loss: 1.3126', '6.4363 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2012/3620', 'Training loss: 1.3117', '6.9162 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2013/3620', 'Training loss: 1.3106', '6.5543 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2014/3620', 'Training loss: 1.3097', '6.7936 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2015/3620', 'Training loss: 1.3095', '6.7839 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2016/3620', 'Training loss: 1.3084', '6.7015 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2017/3620', 'Training loss: 1.3081', '6.5353 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2018/3620', 'Training loss: 1.3079', '6.3473 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2019/3620', 'Training loss: 1.3056', '6.5492 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2020/3620', 'Training loss: 1.3053', '6.4183 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2021/3620', 'Training loss: 1.3041', '7.3009 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2022/3620', 'Training loss: 1.3038', '6.5968 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2023/3620', 'Training loss: 1.3038', '7.0394 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2024/3620', 'Training loss: 1.3035', '6.7272 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2025/3620', 'Training loss: 1.3031', '6.6357 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2026/3620', 'Training loss: 1.3026', '6.3459 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2027/3620', 'Training loss: 1.3028', '6.5439 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2028/3620', 'Training loss: 1.3025', '7.2018 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2029/3620', 'Training loss: 1.3013', '6.4950 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2030/3620', 'Training loss: 1.3003', '6.7884 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2031/3620', 'Training loss: 1.2987', '6.3632 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2032/3620', 'Training loss: 1.2978', '6.5263 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2033/3620', 'Training loss: 1.2973', '6.3171 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2034/3620', 'Training loss: 1.2963', '6.3930 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2035/3620', 'Training loss: 1.2955', '6.4162 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2036/3620', 'Training loss: 1.2958', '6.8629 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2037/3620', 'Training loss: 1.2953', '6.5172 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2038/3620', 'Training loss: 1.2943', '6.6651 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2039/3620', 'Training loss: 1.2939', '6.6113 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2040/3620', 'Training loss: 1.2938', '6.3941 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2041/3620', 'Training loss: 1.2938', '6.0456 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2042/3620', 'Training loss: 1.2933', '6.3139 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2043/3620', 'Training loss: 1.2929', '6.6732 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2044/3620', 'Training loss: 1.2931', '8.3968 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2045/3620', 'Training loss: 1.2927', '6.9336 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2046/3620', 'Training loss: 1.2926', '11.3872 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2047/3620', 'Training loss: 1.2929', '7.8270 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2048/3620', 'Training loss: 1.2929', '11.6151 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2049/3620', 'Training loss: 1.2927', '13.6474 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2050/3620', 'Training loss: 1.2925', '8.4825 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2051/3620', 'Training loss: 1.2923', '9.4615 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2052/3620', 'Training loss: 1.2925', '6.3933 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2053/3620', 'Training loss: 1.2922', '6.3452 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2054/3620', 'Training loss: 1.2923', '6.6320 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2055/3620', 'Training loss: 1.2923', '6.1159 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2056/3620', 'Training loss: 1.2929', '6.8472 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2057/3620', 'Training loss: 1.2936', '6.8377 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2058/3620', 'Training loss: 1.2931', '8.8043 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2059/3620', 'Training loss: 1.2933', '6.5364 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2060/3620', 'Training loss: 1.2929', '6.4817 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2061/3620', 'Training loss: 1.2930', '6.5724 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2062/3620', 'Training loss: 1.2928', '6.3543 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2063/3620', 'Training loss: 1.2929', '6.2985 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2064/3620', 'Training loss: 1.2929', '6.2661 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2065/3620', 'Training loss: 1.2934', '6.5925 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2066/3620', 'Training loss: 1.2935', '6.5078 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2067/3620', 'Training loss: 1.2934', '6.2707 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2068/3620', 'Training loss: 1.2936', '6.5242 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2069/3620', 'Training loss: 1.2932', '6.4322 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2070/3620', 'Training loss: 1.2928', '6.0186 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2071/3620', 'Training loss: 1.2928', '6.4998 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2072/3620', 'Training loss: 1.2926', '6.4308 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2073/3620', 'Training loss: 1.2922', '6.3493 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2074/3620', 'Training loss: 1.2920', '6.5132 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2075/3620', 'Training loss: 1.2916', '6.7158 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2076/3620', 'Training loss: 1.2912', '6.2433 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2077/3620', 'Training loss: 1.2907', '6.1228 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2078/3620', 'Training loss: 1.2902', '6.0691 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2079/3620', 'Training loss: 1.2902', '6.3877 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2080/3620', 'Training loss: 1.2902', '7.2437 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2081/3620', 'Training loss: 1.2900', '6.5938 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2082/3620', 'Training loss: 1.2896', '6.3905 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2083/3620', 'Training loss: 1.2890', '6.6638 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2084/3620', 'Training loss: 1.2889', '6.2753 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2085/3620', 'Training loss: 1.2888', '8.5473 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2086/3620', 'Training loss: 1.2886', '8.5550 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2087/3620', 'Training loss: 1.2884', '7.6342 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2088/3620', 'Training loss: 1.2882', '6.6834 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2089/3620', 'Training loss: 1.2882', '7.4231 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2090/3620', 'Training loss: 1.2880', '7.1102 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2091/3620', 'Training loss: 1.2879', '7.1867 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2092/3620', 'Training loss: 1.2875', '7.3816 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2093/3620', 'Training loss: 1.2870', '9.7178 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2094/3620', 'Training loss: 1.2866', '7.3157 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2095/3620', 'Training loss: 1.2863', '12.6597 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2096/3620', 'Training loss: 1.2864', '10.1279 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2097/3620', 'Training loss: 1.2860', '7.3087 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2098/3620', 'Training loss: 1.2857', '6.7271 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2099/3620', 'Training loss: 1.2858', '6.8010 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2100/3620', 'Training loss: 1.2855', '8.1813 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2101/3620', 'Training loss: 1.2854', '7.1181 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2102/3620', 'Training loss: 1.2851', '6.1990 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2103/3620', 'Training loss: 1.2853', '6.1553 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2104/3620', 'Training loss: 1.2853', '7.3106 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2105/3620', 'Training loss: 1.2853', '7.3816 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2106/3620', 'Training loss: 1.2852', '6.9586 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2107/3620', 'Training loss: 1.2849', '8.2794 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2108/3620', 'Training loss: 1.2848', '5.9737 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2109/3620', 'Training loss: 1.2845', '6.4256 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2110/3620', 'Training loss: 1.2843', '6.8144 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2111/3620', 'Training loss: 1.2842', '6.3954 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2112/3620', 'Training loss: 1.2841', '6.4696 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2113/3620', 'Training loss: 1.2840', '6.3508 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2114/3620', 'Training loss: 1.2839', '6.6867 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2115/3620', 'Training loss: 1.2841', '6.6058 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2116/3620', 'Training loss: 1.2837', '6.5912 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2117/3620', 'Training loss: 1.2833', '8.2813 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2118/3620', 'Training loss: 1.2828', '9.2212 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2119/3620', 'Training loss: 1.2828', '8.2033 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2120/3620', 'Training loss: 1.2827', '6.3397 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2121/3620', 'Training loss: 1.2826', '6.1718 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2122/3620', 'Training loss: 1.2824', '6.3520 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2123/3620', 'Training loss: 1.2823', '6.7154 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2124/3620', 'Training loss: 1.2821', '7.1266 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2125/3620', 'Training loss: 1.2817', '6.6990 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2126/3620', 'Training loss: 1.2815', '7.5422 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2127/3620', 'Training loss: 1.2815', '6.8981 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2128/3620', 'Training loss: 1.2813', '6.8230 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2129/3620', 'Training loss: 1.2814', '7.2436 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2130/3620', 'Training loss: 1.2815', '7.0071 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2131/3620', 'Training loss: 1.2814', '6.9037 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2132/3620', 'Training loss: 1.2814', '6.1957 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2133/3620', 'Training loss: 1.2813', '6.4379 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2134/3620', 'Training loss: 1.2813', '6.8733 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2135/3620', 'Training loss: 1.2814', '9.0664 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2136/3620', 'Training loss: 1.2814', '7.0239 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2137/3620', 'Training loss: 1.2814', '6.7539 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2138/3620', 'Training loss: 1.2814', '6.2461 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2139/3620', 'Training loss: 1.2814', '6.7978 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2140/3620', 'Training loss: 1.2815', '6.2173 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2141/3620', 'Training loss: 1.2815', '6.2594 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2142/3620', 'Training loss: 1.2815', '6.5106 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2143/3620', 'Training loss: 1.2816', '8.0362 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2144/3620', 'Training loss: 1.2818', '6.6273 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2145/3620', 'Training loss: 1.2819', '6.7436 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2146/3620', 'Training loss: 1.2816', '6.8508 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2147/3620', 'Training loss: 1.2815', '6.8873 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2148/3620', 'Training loss: 1.2812', '6.8416 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2149/3620', 'Training loss: 1.2813', '6.8961 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2150/3620', 'Training loss: 1.2812', '7.3562 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2151/3620', 'Training loss: 1.2812', '7.4574 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2152/3620', 'Training loss: 1.2813', '6.8601 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2153/3620', 'Training loss: 1.2812', '7.2188 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2154/3620', 'Training loss: 1.2809', '7.0499 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2155/3620', 'Training loss: 1.2808', '6.7089 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2156/3620', 'Training loss: 1.2807', '7.6452 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2157/3620', 'Training loss: 1.2808', '6.8342 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2158/3620', 'Training loss: 1.2809', '6.8523 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2159/3620', 'Training loss: 1.2807', '7.0400 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2160/3620', 'Training loss: 1.2806', '6.8050 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2161/3620', 'Training loss: 1.2808', '6.8156 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2162/3620', 'Training loss: 1.2808', '6.4134 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2163/3620', 'Training loss: 1.2811', '7.0765 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2164/3620', 'Training loss: 1.2811', '6.3924 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2165/3620', 'Training loss: 1.2810', '6.3218 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2166/3620', 'Training loss: 1.2810', '7.0771 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2167/3620', 'Training loss: 1.2809', '6.4869 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2168/3620', 'Training loss: 1.2807', '6.4271 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2169/3620', 'Training loss: 1.2808', '6.6806 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2170/3620', 'Training loss: 1.2807', '6.5366 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2171/3620', 'Training loss: 1.2807', '6.7290 sec/batch')\n",
      "('Epoch 12/20 ', 'Iteration 2172/3620', 'Training loss: 1.2806', '7.7470 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2173/3620', 'Training loss: 1.4024', '6.7256 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2174/3620', 'Training loss: 1.3397', '7.3752 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2175/3620', 'Training loss: 1.3199', '7.1260 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2176/3620', 'Training loss: 1.3162', '6.5563 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2177/3620', 'Training loss: 1.3113', '9.3367 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2178/3620', 'Training loss: 1.3084', '7.3032 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2179/3620', 'Training loss: 1.3011', '7.7028 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2180/3620', 'Training loss: 1.2992', '6.9518 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2181/3620', 'Training loss: 1.2957', '7.2037 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2182/3620', 'Training loss: 1.2912', '6.6931 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2183/3620', 'Training loss: 1.2913', '6.7494 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2184/3620', 'Training loss: 1.2883', '6.3602 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2185/3620', 'Training loss: 1.2879', '6.2071 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2186/3620', 'Training loss: 1.2864', '6.1887 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2187/3620', 'Training loss: 1.2867', '6.1755 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2188/3620', 'Training loss: 1.2837', '6.0347 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2189/3620', 'Training loss: 1.2812', '6.2002 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2190/3620', 'Training loss: 1.2814', '6.0921 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2191/3620', 'Training loss: 1.2815', '6.0943 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2192/3620', 'Training loss: 1.2828', '6.1090 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2193/3620', 'Training loss: 1.2820', '6.1168 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2194/3620', 'Training loss: 1.2811', '6.6621 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2195/3620', 'Training loss: 1.2804', '6.0863 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2196/3620', 'Training loss: 1.2806', '6.1431 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2197/3620', 'Training loss: 1.2799', '6.2527 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2198/3620', 'Training loss: 1.2798', '6.0543 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2199/3620', 'Training loss: 1.2796', '6.0674 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2200/3620', 'Training loss: 1.2774', '6.0941 sec/batch')\n",
      "('Validation loss:', 1.1755028, 'Saving checkpoint!')\n",
      "('Epoch 13/20 ', 'Iteration 2201/3620', 'Training loss: 1.2834', '6.9737 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2202/3620', 'Training loss: 1.2828', '6.0034 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2203/3620', 'Training loss: 1.2823', '6.0895 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2204/3620', 'Training loss: 1.2825', '6.1029 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2205/3620', 'Training loss: 1.2824', '6.0613 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2206/3620', 'Training loss: 1.2817', '6.6252 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2207/3620', 'Training loss: 1.2811', '6.1528 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2208/3620', 'Training loss: 1.2816', '6.1202 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2209/3620', 'Training loss: 1.2811', '6.1061 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2210/3620', 'Training loss: 1.2798', '6.0849 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2211/3620', 'Training loss: 1.2787', '6.1170 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2212/3620', 'Training loss: 1.2770', '6.0836 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2213/3620', 'Training loss: 1.2761', '6.7907 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2214/3620', 'Training loss: 1.2756', '5.9085 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2215/3620', 'Training loss: 1.2746', '6.0182 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2216/3620', 'Training loss: 1.2738', '6.1951 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2217/3620', 'Training loss: 1.2741', '6.2352 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2218/3620', 'Training loss: 1.2736', '6.0793 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2219/3620', 'Training loss: 1.2728', '6.5890 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2220/3620', 'Training loss: 1.2723', '8.3641 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2221/3620', 'Training loss: 1.2721', '10.6320 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2222/3620', 'Training loss: 1.2720', '6.5467 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2223/3620', 'Training loss: 1.2717', '6.9808 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2224/3620', 'Training loss: 1.2711', '7.2475 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2225/3620', 'Training loss: 1.2712', '8.8328 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2226/3620', 'Training loss: 1.2710', '6.1766 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2227/3620', 'Training loss: 1.2709', '6.2533 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2228/3620', 'Training loss: 1.2710', '6.5154 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2229/3620', 'Training loss: 1.2708', '7.9362 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2230/3620', 'Training loss: 1.2707', '6.7922 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2231/3620', 'Training loss: 1.2706', '8.5765 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2232/3620', 'Training loss: 1.2704', '6.7033 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2233/3620', 'Training loss: 1.2706', '6.6327 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2234/3620', 'Training loss: 1.2704', '5.9661 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2235/3620', 'Training loss: 1.2704', '6.5587 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2236/3620', 'Training loss: 1.2705', '6.6991 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2237/3620', 'Training loss: 1.2710', '6.5303 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2238/3620', 'Training loss: 1.2717', '6.1431 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2239/3620', 'Training loss: 1.2712', '6.3206 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2240/3620', 'Training loss: 1.2713', '6.1382 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2241/3620', 'Training loss: 1.2709', '6.4084 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2242/3620', 'Training loss: 1.2708', '6.5416 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2243/3620', 'Training loss: 1.2706', '6.6119 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2244/3620', 'Training loss: 1.2705', '6.2995 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2245/3620', 'Training loss: 1.2705', '7.0360 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2246/3620', 'Training loss: 1.2709', '8.4903 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2247/3620', 'Training loss: 1.2710', '8.0387 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2248/3620', 'Training loss: 1.2708', '7.2522 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2249/3620', 'Training loss: 1.2709', '6.5382 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2250/3620', 'Training loss: 1.2706', '6.3568 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2251/3620', 'Training loss: 1.2701', '8.9120 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2252/3620', 'Training loss: 1.2699', '6.6084 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2253/3620', 'Training loss: 1.2697', '6.9701 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2254/3620', 'Training loss: 1.2693', '10.9016 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2255/3620', 'Training loss: 1.2693', '10.7127 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2256/3620', 'Training loss: 1.2688', '7.2911 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2257/3620', 'Training loss: 1.2683', '7.4230 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2258/3620', 'Training loss: 1.2680', '6.5681 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2259/3620', 'Training loss: 1.2674', '9.5568 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2260/3620', 'Training loss: 1.2673', '6.9031 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2261/3620', 'Training loss: 1.2673', '7.3807 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2262/3620', 'Training loss: 1.2671', '7.1975 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2263/3620', 'Training loss: 1.2669', '6.9589 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2264/3620', 'Training loss: 1.2664', '8.0705 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2265/3620', 'Training loss: 1.2664', '6.6590 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2266/3620', 'Training loss: 1.2662', '6.3239 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2267/3620', 'Training loss: 1.2659', '6.3178 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2268/3620', 'Training loss: 1.2658', '6.5812 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2269/3620', 'Training loss: 1.2656', '7.6952 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2270/3620', 'Training loss: 1.2656', '6.9248 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2271/3620', 'Training loss: 1.2654', '6.1904 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2272/3620', 'Training loss: 1.2652', '6.2756 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2273/3620', 'Training loss: 1.2648', '7.9748 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2274/3620', 'Training loss: 1.2644', '6.4342 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2275/3620', 'Training loss: 1.2641', '6.4165 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2276/3620', 'Training loss: 1.2638', '6.4006 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2277/3620', 'Training loss: 1.2638', '6.2214 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2278/3620', 'Training loss: 1.2635', '6.5915 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2279/3620', 'Training loss: 1.2633', '6.2227 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2280/3620', 'Training loss: 1.2634', '6.8548 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2281/3620', 'Training loss: 1.2631', '6.9510 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2282/3620', 'Training loss: 1.2629', '6.4881 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2283/3620', 'Training loss: 1.2627', '6.3562 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2284/3620', 'Training loss: 1.2629', '8.4992 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2285/3620', 'Training loss: 1.2629', '6.6518 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2286/3620', 'Training loss: 1.2628', '6.6063 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2287/3620', 'Training loss: 1.2629', '7.1462 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2288/3620', 'Training loss: 1.2626', '7.9781 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2289/3620', 'Training loss: 1.2625', '6.9443 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2290/3620', 'Training loss: 1.2623', '7.1426 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2291/3620', 'Training loss: 1.2622', '7.6450 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2292/3620', 'Training loss: 1.2620', '6.3650 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2293/3620', 'Training loss: 1.2618', '6.7471 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2294/3620', 'Training loss: 1.2618', '6.8258 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2295/3620', 'Training loss: 1.2617', '6.7451 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2296/3620', 'Training loss: 1.2617', '7.0593 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2297/3620', 'Training loss: 1.2614', '8.0105 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2298/3620', 'Training loss: 1.2610', '6.2790 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2299/3620', 'Training loss: 1.2605', '6.7296 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2300/3620', 'Training loss: 1.2604', '7.1706 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2301/3620', 'Training loss: 1.2604', '7.5606 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2302/3620', 'Training loss: 1.2602', '6.8928 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2303/3620', 'Training loss: 1.2600', '8.8325 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2304/3620', 'Training loss: 1.2600', '8.5642 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2305/3620', 'Training loss: 1.2598', '7.7095 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2306/3620', 'Training loss: 1.2594', '6.7218 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2307/3620', 'Training loss: 1.2592', '7.1744 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2308/3620', 'Training loss: 1.2591', '8.1769 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2309/3620', 'Training loss: 1.2590', '6.8469 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2310/3620', 'Training loss: 1.2590', '7.0920 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2311/3620', 'Training loss: 1.2591', '7.4628 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2312/3620', 'Training loss: 1.2589', '7.2945 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2313/3620', 'Training loss: 1.2590', '7.0426 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2314/3620', 'Training loss: 1.2590', '7.8965 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2315/3620', 'Training loss: 1.2590', '7.6936 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2316/3620', 'Training loss: 1.2591', '7.5482 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2317/3620', 'Training loss: 1.2591', '7.0520 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2318/3620', 'Training loss: 1.2591', '7.1485 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2319/3620', 'Training loss: 1.2590', '7.8574 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2320/3620', 'Training loss: 1.2591', '7.2549 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2321/3620', 'Training loss: 1.2593', '6.9767 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2322/3620', 'Training loss: 1.2592', '7.2267 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2323/3620', 'Training loss: 1.2594', '7.9224 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2324/3620', 'Training loss: 1.2594', '8.1446 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2325/3620', 'Training loss: 1.2596', '8.9855 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2326/3620', 'Training loss: 1.2596', '7.5359 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2327/3620', 'Training loss: 1.2594', '7.6191 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2328/3620', 'Training loss: 1.2593', '7.3556 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2329/3620', 'Training loss: 1.2591', '7.2113 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2330/3620', 'Training loss: 1.2592', '6.9083 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2331/3620', 'Training loss: 1.2591', '7.0317 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2332/3620', 'Training loss: 1.2592', '7.0604 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2333/3620', 'Training loss: 1.2592', '7.2149 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2334/3620', 'Training loss: 1.2591', '7.3126 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2335/3620', 'Training loss: 1.2588', '7.0672 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2336/3620', 'Training loss: 1.2586', '7.1911 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2337/3620', 'Training loss: 1.2585', '6.3936 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2338/3620', 'Training loss: 1.2586', '7.1777 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2339/3620', 'Training loss: 1.2587', '6.6311 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2340/3620', 'Training loss: 1.2585', '6.4169 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2341/3620', 'Training loss: 1.2584', '7.5619 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2342/3620', 'Training loss: 1.2586', '7.4996 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2343/3620', 'Training loss: 1.2587', '6.3273 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2344/3620', 'Training loss: 1.2589', '6.3041 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2345/3620', 'Training loss: 1.2590', '7.8120 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2346/3620', 'Training loss: 1.2589', '7.7756 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2347/3620', 'Training loss: 1.2589', '7.4143 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2348/3620', 'Training loss: 1.2587', '7.0171 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2349/3620', 'Training loss: 1.2585', '6.9946 sec/batch')\n",
      "('Epoch 13/20 ', 'Iteration 2350/3620', 'Training loss: 1.2586', '7.3324 sec/batch')\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "# Save every N iterations\n",
    "save_every_n = 200\n",
    "train_x, train_y, val_x, val_y = split_data(chars, batch_size, num_steps)\n",
    "\n",
    "model = build_rnn(len(vocab), \n",
    "                  batch_size=batch_size,\n",
    "                  num_steps=num_steps,\n",
    "                  learning_rate=learning_rate,\n",
    "                  lstm_size=lstm_size,\n",
    "                  num_layers=num_layers)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "    #saver.restore(sess, 'checkpoints/______.ckpt')\n",
    "    \n",
    "    n_batches = int(train_x.shape[1]/num_steps)\n",
    "    iterations = n_batches * epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for b, (x, y) in enumerate(get_batch([train_x, train_y], num_steps), 1):\n",
    "            iteration = e*n_batches + b\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.cost, model.final_state, model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            loss += batch_loss\n",
    "            end = time.time()\n",
    "            print('Epoch {}/{} '.format(e+1, epochs),\n",
    "                  'Iteration {}/{}'.format(iteration, iterations),\n",
    "                  'Training loss: {:.4f}'.format(loss/b),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            \n",
    "            if (iteration%save_every_n == 0) or (iteration == iterations):\n",
    "                # Check performance, notice dropout has been set to 1\n",
    "                val_loss = []\n",
    "                new_state = sess.run(model.initial_state)\n",
    "                for x, y in get_batch([val_x, val_y], num_steps):\n",
    "                    feed = {model.inputs: x,\n",
    "                            model.targets: y,\n",
    "                            model.keep_prob: 1.,\n",
    "                            model.initial_state: new_state}\n",
    "                    batch_loss, new_state = sess.run([model.cost, model.final_state], feed_dict=feed)\n",
    "                    val_loss.append(batch_loss)\n",
    "\n",
    "                print('Validation loss:', np.mean(val_loss),\n",
    "                      'Saving checkpoint!')\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}_v{:.3f}.ckpt\".format(iteration, lstm_size, np.mean(val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Saved checkpoints\n",
    "\n",
    "Read up on saving and loading checkpoints here: https://www.tensorflow.org/programmers_guide/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.train.get_checkpoint_state('checkpoints')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sampling\n",
    "\n",
    "Now that the network is trained, we'll can use it to generate new text. The idea is that we pass in a character, then the network will predict the next character. We can use the new one, to predict the next one. And we keep doing this to generate all new text. I also included some functionality to prime the network with some text by passing in a string and building up a state from that.\n",
    "\n",
    "The network gives us predictions for each character. To reduce noise and make things a little less random, I'm going to only choose a new character from the top N most likely characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pick_top_n(preds, vocab_size, top_n=5):\n",
    "    p = np.squeeze(preds)\n",
    "    p[np.argsort(p)[:-top_n]] = 0\n",
    "    p = p / np.sum(p)\n",
    "    c = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sample(checkpoint, n_samples, lstm_size, vocab_size, prime=\"The \"):\n",
    "    samples = [c for c in prime]\n",
    "    model = build_rnn(vocab_size, lstm_size=lstm_size, sampling=True)\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, checkpoint)\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        for c in prime:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0,0] = vocab_to_int[c]\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.preds, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "        c = pick_top_n(preds, len(vocab))\n",
    "        samples.append(int_to_vocab[c])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            x[0,0] = c\n",
    "            feed = {model.inputs: x,\n",
    "                    model.keep_prob: 1.,\n",
    "                    model.initial_state: new_state}\n",
    "            preds, new_state = sess.run([model.preds, model.final_state], \n",
    "                                         feed_dict=feed)\n",
    "\n",
    "            c = pick_top_n(preds, len(vocab))\n",
    "            samples.append(int_to_vocab[c])\n",
    "        \n",
    "    return ''.join(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here, pass in the path to a checkpoint and sample from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "checkpoint = \"checkpoints/____.ckpt\"\n",
    "samp = sample(checkpoint, 2000, lstm_size, len(vocab), prime=\"Far\")\n",
    "print(samp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
